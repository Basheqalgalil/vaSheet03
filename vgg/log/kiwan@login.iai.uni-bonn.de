<?xml version="1.0" encoding="UTF-8"?>
<configuration-tree>
   |-
     |-log-file:log/training.log
     |-action:training
     |-source-type:single
     |-target-type:single
     |-batch-size:55
     |-features
       |-aligned-feature-reader
         |-feature-cache:features/train.frames
         |-target-cache:features/train.labels
         |-shuffle-buffer:true
         |-buffer-size:10000
         |-preprocessors:subtract-mean
     |-subtract-mean
       |-type:vector-subtraction
       |-vector:imagenet/mean.vector.gz
     |-*
       |-trainer:feed-forward-trainer
       |-training-criterion:cross-entropy
       |-weight-initialization:zero
       |-bias-initialization:zero
       |-regularizer:l2-regularizer
       |-regularization-constant:0.0005
     |-trainer
       |-task:classification
       |-number-of-epochs:5
       |-save-frequency:0
     |-estimator
       |-method:steepest-descent
       |-use-momentum:true
       |-momentum:0.9
     |-learning-rate-schedule
       |-method:step
       |-initial-learning-rate:0.001
       |-reduce-after-iterations:300
       |-reduction-factor:0.1
     |-neural-network
       |-connections:conv1_1,conv1_2,pool1,conv2_1,conv2_2,pool2,conv3_1,conv3_2,conv3_3,pool3,conv4_1,conv4_2,conv4_3,pool4,conv5_1,conv5_2,conv5_3,pool5,fc6,fc7,fc8
       |-input-dimension:150528
       |-source-width:224
       |-source-height:224
       |-source-channels:3
       |-conv1_1
         |-from:network-input
         |-to:relu1_1
         |-type:convolutional-connection
         |-kernel-width:3
         |-kernel-height:3
         |-dest-channels:64
       |-conv1_2
         |-from:relu1_1
         |-to:relu1_2
         |-type:convolutional-connection
         |-kernel-width:3
         |-kernel-height:3
         |-dest-channels:64
       |-pool1
         |-from:relu1_2
         |-to:maxpool1
         |-type:plain-connection
       |-conv2_1
         |-from:maxpool1
         |-to:relu2_1
         |-type:convolutional-connection
         |-kernel-width:3
         |-kernel-height:3
         |-dest-channels:128
       |-conv2_2
         |-from:relu2_1
         |-to:relu2_2
         |-type:convolutional-connection
         |-kernel-width:3
         |-kernel-height:3
         |-dest-channels:128
       |-pool2
         |-from:relu2_2
         |-to:maxpool2
         |-type:plain-connection
       |-conv3_1
         |-from:maxpool2
         |-to:relu3_1
         |-type:convolutional-connection
         |-kernel-width:3
         |-kernel-height:3
         |-dest-channels:256
       |-conv3_2
         |-from:relu3_1
         |-to:relu3_2
         |-type:convolutional-connection
         |-kernel-width:3
         |-kernel-height:3
         |-dest-channels:256
       |-conv3_3
         |-from:relu3_2
         |-to:relu3_3
         |-type:convolutional-connection
         |-kernel-width:3
         |-kernel-height:3
         |-dest-channels:256
       |-pool3
         |-from:relu3_3
         |-to:maxpool3
         |-type:plain-connection
       |-conv4_1
         |-from:maxpool3
         |-to:relu4_1
         |-type:convolutional-connection
         |-kernel-width:3
         |-kernel-height:3
         |-dest-channels:512
       |-conv4_2
         |-from:relu4_1
         |-to:relu4_2
         |-type:convolutional-connection
         |-kernel-width:3
         |-kernel-height:3
         |-dest-channels:512
       |-conv4_3
         |-from:relu4_2
         |-to:relu4_3
         |-type:convolutional-connection
         |-kernel-width:3
         |-kernel-height:3
         |-dest-channels:512
       |-pool4
         |-from:relu4_3
         |-to:maxpool4
         |-type:plain-connection
       |-conv5_1
         |-from:maxpool4
         |-to:relu5_1
         |-type:convolutional-connection
         |-kernel-width:3
         |-kernel-height:3
         |-dest-channels:512
       |-conv5_2
         |-from:relu5_1
         |-to:relu5_2
         |-type:convolutional-connection
         |-kernel-width:3
         |-kernel-height:3
         |-dest-channels:512
       |-conv5_3
         |-from:relu5_2
         |-to:relu5_3
         |-type:convolutional-connection
         |-kernel-width:3
         |-kernel-height:3
         |-dest-channels:512
       |-pool5
         |-from:relu5_3
         |-to:maxpool5
         |-type:plain-connection
       |-fc6
         |-from:maxpool5
         |-to:layer-6
         |-type:weight-connection
       |-fc7
         |-from:layer-6
         |-to:layer-7
         |-type:weight-connection
       |-fc8
         |-from:layer-7
         |-to:layer-8
         |-type:weight-connection
       |-relu1_1
         |-type:rectified
       |-relu1_2
         |-type:rectified
       |-maxpool1
         |-type:max-pooling
         |-grid-size:2
         |-stride:2
         |-use-bias:false
         |-use-cudnn:false
       |-relu2_1
         |-type:rectified
       |-relu2_2
         |-type:rectified
       |-maxpool2
         |-type:max-pooling
         |-grid-size:2
         |-stride:2
         |-use-bias:false
         |-use-cudnn:false
       |-relu3_1
         |-type:rectified
       |-relu3_2
         |-type:rectified
       |-relu3_3
         |-type:rectified
       |-maxpool3
         |-type:max-pooling
         |-grid-size:2
         |-stride:2
         |-use-bias:false
         |-use-cudnn:false
       |-relu4_1
         |-type:rectified
       |-relu4_2
         |-type:rectified
       |-relu4_3
         |-type:rectified
       |-maxpool4
         |-type:max-pooling
         |-grid-size:2
         |-stride:2
         |-use-bias:false
         |-use-cudnn:false
       |-relu5_1
         |-type:rectified
       |-relu5_2
         |-type:rectified
       |-relu5_3
         |-type:rectified
       |-maxpool5
         |-type:max-pooling
         |-grid-size:2
         |-stride:2
         |-use-bias:false
         |-use-cudnn:false
       |-layer-6
         |-number-of-units:4096
         |-type:rectified
         |-dropout-probability:0.9
       |-layer-7
         |-number-of-units:4096
         |-type:rectified
         |-dropout-probability:0.9
       |-layer-8
         |-number-of-units:12
         |-type:softmax
       |-write-model-to:results
       |-load-model-from:imagenet
     |-config:config/training.config
</configuration-tree>
Create feed-forward-trainer.
<cuda>
  using 1 of 2 GPUs
</cuda>
<neural-network.initialize>
  Create rectified layer.
  Create Convolutional Connection.
  Create rectified layer.
  Create Convolutional Connection.
  Create max-pooling layer.
  Create Plain Connection.
  Create rectified layer.
  Create Convolutional Connection.
  Create rectified layer.
  Create Convolutional Connection.
  Create max-pooling layer.
  Create Plain Connection.
  Create rectified layer.
  Create Convolutional Connection.
  Create rectified layer.
  Create Convolutional Connection.
  Create rectified layer.
  Create Convolutional Connection.
  Create max-pooling layer.
  Create Plain Connection.
  Create rectified layer.
  Create Convolutional Connection.
  Create rectified layer.
  Create Convolutional Connection.
  Create rectified layer.
  Create Convolutional Connection.
  Create max-pooling layer.
  Create Plain Connection.
  Create rectified layer.
  Create Convolutional Connection.
  Create rectified layer.
  Create Convolutional Connection.
  Create rectified layer.
  Create Convolutional Connection.
  Create max-pooling layer.
  Create Plain Connection.
  Create rectified layer.
  Create rectified layer.
  Create softmax layer.
  <topological-order>
    relu1_1
    relu1_2
    maxpool1
    relu2_1
    relu2_2
    maxpool2
    relu3_1
    relu3_2
    relu3_3
    maxpool3
    relu4_1
    relu4_2
    relu4_3
    maxpool4
    relu5_1
    relu5_2
    relu5_3
    maxpool5
    layer-6
    layer-7
    layer-8
  </topological-order>
  <neural-network.topology>
    <relu1_1>
      incoming connections to input port 0: network-input:port-0
      outgoing connections from output port 0: relu1_2:port-0
    </relu1_1>
    <relu1_2>
      incoming connections to input port 0: relu1_1:port-0
      outgoing connections from output port 0: maxpool1:port-0
    </relu1_2>
    <maxpool1>
      incoming connections to input port 0: relu1_2:port-0
      outgoing connections from output port 0: relu2_1:port-0
    </maxpool1>
    <relu2_1>
      incoming connections to input port 0: maxpool1:port-0
      outgoing connections from output port 0: relu2_2:port-0
    </relu2_1>
    <relu2_2>
      incoming connections to input port 0: relu2_1:port-0
      outgoing connections from output port 0: maxpool2:port-0
    </relu2_2>
    <maxpool2>
      incoming connections to input port 0: relu2_2:port-0
      outgoing connections from output port 0: relu3_1:port-0
    </maxpool2>
    <relu3_1>
      incoming connections to input port 0: maxpool2:port-0
      outgoing connections from output port 0: relu3_2:port-0
    </relu3_1>
    <relu3_2>
      incoming connections to input port 0: relu3_1:port-0
      outgoing connections from output port 0: relu3_3:port-0
    </relu3_2>
    <relu3_3>
      incoming connections to input port 0: relu3_2:port-0
      outgoing connections from output port 0: maxpool3:port-0
    </relu3_3>
    <maxpool3>
      incoming connections to input port 0: relu3_3:port-0
      outgoing connections from output port 0: relu4_1:port-0
    </maxpool3>
    <relu4_1>
      incoming connections to input port 0: maxpool3:port-0
      outgoing connections from output port 0: relu4_2:port-0
    </relu4_1>
    <relu4_2>
      incoming connections to input port 0: relu4_1:port-0
      outgoing connections from output port 0: relu4_3:port-0
    </relu4_2>
    <relu4_3>
      incoming connections to input port 0: relu4_2:port-0
      outgoing connections from output port 0: maxpool4:port-0
    </relu4_3>
    <maxpool4>
      incoming connections to input port 0: relu4_3:port-0
      outgoing connections from output port 0: relu5_1:port-0
    </maxpool4>
    <relu5_1>
      incoming connections to input port 0: maxpool4:port-0
      outgoing connections from output port 0: relu5_2:port-0
    </relu5_1>
    <relu5_2>
      incoming connections to input port 0: relu5_1:port-0
      outgoing connections from output port 0: relu5_3:port-0
    </relu5_2>
    <relu5_3>
      incoming connections to input port 0: relu5_2:port-0
      outgoing connections from output port 0: maxpool5:port-0
    </relu5_3>
    <maxpool5>
      incoming connections to input port 0: relu5_3:port-0
      outgoing connections from output port 0: layer-6:port-0
    </maxpool5>
    <layer-6>
      incoming connections to input port 0: maxpool5:port-0
      outgoing connections from output port 0: layer-7:port-0
    </layer-6>
    <layer-7>
      incoming connections to input port 0: layer-6:port-0
      outgoing connections from output port 0: layer-8:port-0
    </layer-7>
    <layer-8>
      incoming connections to input port 0: layer-7:port-0
      outgoing connections from output port 0:
    </layer-8>
  </neural-network.topology>
  Layer relu1_1:0: read bias from imagenet/bias-relu1_1.vector.gz
  Layer relu1_2:0: read bias from imagenet/bias-relu1_2.vector.gz
  Layer relu2_1:0: read bias from imagenet/bias-relu2_1.vector.gz
  Layer relu2_2:0: read bias from imagenet/bias-relu2_2.vector.gz
  Layer relu3_1:0: read bias from imagenet/bias-relu3_1.vector.gz
  Layer relu3_2:0: read bias from imagenet/bias-relu3_2.vector.gz
  Layer relu3_3:0: read bias from imagenet/bias-relu3_3.vector.gz
  Layer relu4_1:0: read bias from imagenet/bias-relu4_1.vector.gz
  Layer relu4_2:0: read bias from imagenet/bias-relu4_2.vector.gz
  Layer relu4_3:0: read bias from imagenet/bias-relu4_3.vector.gz
  Layer relu5_1:0: read bias from imagenet/bias-relu5_1.vector.gz
  Layer relu5_2:0: read bias from imagenet/bias-relu5_2.vector.gz
  Layer relu5_3:0: read bias from imagenet/bias-relu5_3.vector.gz
  Use dropout probablility 0.9 in layer layer-6
  Layer layer-6:0: read bias from imagenet/bias-layer-6.vector.gz
  Use dropout probablility 0.9 in layer layer-7
  Layer layer-7:0: read bias from imagenet/bias-layer-7.vector.gz
  Layer layer-8: no file to load bias from. Use initialization: zero
  Connection conv1_1: read weight matrix from imagenet/weights-conv1_1.matrix.gz
  Connection conv1_2: read weight matrix from imagenet/weights-conv1_2.matrix.gz
  Connection conv2_1: read weight matrix from imagenet/weights-conv2_1.matrix.gz
  Connection conv2_2: read weight matrix from imagenet/weights-conv2_2.matrix.gz
  Connection conv3_1: read weight matrix from imagenet/weights-conv3_1.matrix.gz
  Connection conv3_2: read weight matrix from imagenet/weights-conv3_2.matrix.gz
  Connection conv3_3: read weight matrix from imagenet/weights-conv3_3.matrix.gz
  Connection conv4_1: read weight matrix from imagenet/weights-conv4_1.matrix.gz
  Connection conv4_2: read weight matrix from imagenet/weights-conv4_2.matrix.gz
  Connection conv4_3: read weight matrix from imagenet/weights-conv4_3.matrix.gz
  Connection conv5_1: read weight matrix from imagenet/weights-conv5_1.matrix.gz
  Connection conv5_2: read weight matrix from imagenet/weights-conv5_2.matrix.gz
  Connection conv5_3: read weight matrix from imagenet/weights-conv5_3.matrix.gz
  Connection fc6: read weight matrix from imagenet/weights-fc6.matrix.gz
  Connection fc7: read weight matrix from imagenet/weights-fc7.matrix.gz
  Connection fc8 BasePath:imagenet/
  Connection fc8 imagenet/weights-fc8.matrix.gz doesn't exists
  Connection fc8: no file to load weights from. Use zero initialization.
</neural-network.initialize>
<feature-cache.information features/train.frames>
  feature type: videos
  total number of feature vectors: 9630
  feature vector dimension: 150528
  number of feature sequences: 227
</feature-cache.information>
Create vector-subtraction preprocessor as subtract-mean.
<math.random>
  invoke srand with seed 1672324
</math.random>
<feature-cache.information features/train.labels>
  feature type: sequencelabels
  total number of feature vectors: 9630
  feature vector dimension: 12
  number of feature sequences: 227
</feature-cache.information>
Create steepest-descent estimator.
Create step learning rate scheduler.
initial learning rate: 0.001
reduce-after-iterations: 300
reduction-factor: 0.1
Create l2-regularizer.
Use cross-entropy criterion.
<neural-network.process-all-epochs>
  Start epoch 1
  <neural-network.process-epoch>
    <neural-network.process-batch>
      Process mini-batch 1 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352748
      gradient-norm: 6290.42
      step size: 6.29042
      objective function value: 3.46194
      classification error rate: 0.8
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 2 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352754
      gradient-norm: 17933
      step size: 21.7656
      objective function value: 3.45247
      classification error rate: 0.909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 3 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352763
      gradient-norm: 31702.5
      step size: 44.4672
      objective function value: 3.33363
      classification error rate: 0.818182
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 4 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352772
      gradient-norm: 45714.9
      step size: 72.7817
      objective function value: 3.53563
      classification error rate: 0.909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 5 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352783
      gradient-norm: 56990
      step size: 104.785
      objective function value: 3.31369
      classification error rate: 0.854545
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 6 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352794
      gradient-norm: 67854.4
      step size: 137.273
      objective function value: 3.12177
      classification error rate: 0.690909
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 7 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352806
      gradient-norm: 74632
      step size: 168.816
      objective function value: 3.05473
      classification error rate: 0.690909
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 8 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352817
      gradient-norm: 84054.8
      step size: 202.036
      objective function value: 3.01145
      classification error rate: 0.636364
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 9 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352829
      gradient-norm: 103216
      step size: 243.639
      objective function value: 3.01872
      classification error rate: 0.618182
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 10 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352841
      gradient-norm: 113201
      step size: 282.555
      objective function value: 3.1432
      classification error rate: 0.672727
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 11 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352853
      gradient-norm: 110191
      step size: 312.446
      objective function value: 3.0821
      classification error rate: 0.618182
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 12 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352865
      gradient-norm: 99522
      step size: 331.655
      objective function value: 2.81785
      classification error rate: 0.6
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 13 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352878
      gradient-norm: 112143
      step size: 355.016
      objective function value: 3.21059
      classification error rate: 0.672727
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 14 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352890
      gradient-norm: 122110
      step size: 386.287
      objective function value: 3.34739
      classification error rate: 0.709091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 15 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352903
      gradient-norm: 101742
      step size: 394.144
      objective function value: 3.19888
      classification error rate: 0.818182
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 16 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352916
      gradient-norm: 103784
      step size: 402.741
      objective function value: 3.23256
      classification error rate: 0.709091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 17 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352929
      gradient-norm: 94532
      step size: 402.819
      objective function value: 2.92393
      classification error rate: 0.636364
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 18 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352943
      gradient-norm: 99279.9
      step size: 406.775
      objective function value: 3.03676
      classification error rate: 0.763636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 19 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352957
      gradient-norm: 108077
      step size: 419.341
      objective function value: 3.18313
      classification error rate: 0.709091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 20 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352972
      gradient-norm: 100000
      step size: 423.921
      objective function value: 2.68564
      classification error rate: 0.618182
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 21 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 352986
      gradient-norm: 95581.8
      step size: 425.857
      objective function value: 2.83348
      classification error rate: 0.581818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 22 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353002
      gradient-norm: 86194.6
      step size: 418.689
      objective function value: 2.60078
      classification error rate: 0.527273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 23 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353017
      gradient-norm: 109208
      step size: 425.776
      objective function value: 2.71257
      classification error rate: 0.527273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 24 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353032
      gradient-norm: 93146.5
      step size: 422.672
      objective function value: 2.52895
      classification error rate: 0.4
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 25 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353048
      gradient-norm: 103599
      step size: 432.319
      objective function value: 2.74488
      classification error rate: 0.6
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 26 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353063
      gradient-norm: 94709.6
      step size: 434.561
      objective function value: 2.31098
      classification error rate: 0.418182
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 27 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353079
      gradient-norm: 104959
      step size: 437.968
      objective function value: 2.76204
      classification error rate: 0.618182
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 28 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353095
      gradient-norm: 61605.2
      step size: 418.573
      objective function value: 2.00193
      classification error rate: 0.327273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 29 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353112
      gradient-norm: 90049.5
      step size: 418.879
      objective function value: 2.35903
      classification error rate: 0.436364
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 30 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353129
      gradient-norm: 96267.9
      step size: 420.972
      objective function value: 2.46932
      classification error rate: 0.472727
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 31 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353145
      gradient-norm: 86925.3
      step size: 422.356
      objective function value: 2.38711
      classification error rate: 0.381818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 32 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353162
      gradient-norm: 86503.9
      step size: 414.684
      objective function value: 2.1936
      classification error rate: 0.363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 33 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353179
      gradient-norm: 95093.6
      step size: 416.84
      objective function value: 2.58252
      classification error rate: 0.472727
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 34 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353196
      gradient-norm: 122200
      step size: 431.977
      objective function value: 2.83077
      classification error rate: 0.563636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 35 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353212
      gradient-norm: 94691.7
      step size: 428.437
      objective function value: 2.40037
      classification error rate: 0.490909
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 36 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353229
      gradient-norm: 78816.1
      step size: 419.146
      objective function value: 2.19997
      classification error rate: 0.363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 37 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353245
      gradient-norm: 75723.9
      step size: 410.93
      objective function value: 2.04684
      classification error rate: 0.381818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 38 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353263
      gradient-norm: 72116.4
      step size: 402.162
      objective function value: 2.36096
      classification error rate: 0.381818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 39 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353280
      gradient-norm: 57522.3
      step size: 381.807
      objective function value: 1.8593
      classification error rate: 0.309091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 40 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353297
      gradient-norm: 69550.7
      step size: 373.673
      objective function value: 1.99068
      classification error rate: 0.272727
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 41 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353313
      gradient-norm: 96757.1
      step size: 384.752
      objective function value: 2.55478
      classification error rate: 0.509091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 42 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353330
      gradient-norm: 80246.3
      step size: 381.098
      objective function value: 2.46768
      classification error rate: 0.454545
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 43 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353346
      gradient-norm: 75498.6
      step size: 376.361
      objective function value: 2.29063
      classification error rate: 0.436364
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 44 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353363
      gradient-norm: 63677.6
      step size: 364.336
      objective function value: 2.18261
      classification error rate: 0.4
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 45 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353379
      gradient-norm: 60938.9
      step size: 353.332
      objective function value: 1.87244
      classification error rate: 0.309091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 46 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353395
      gradient-norm: 69349.3
      step size: 348.453
      objective function value: 2.20423
      classification error rate: 0.454545
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 47 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353411
      gradient-norm: 72046.9
      step size: 346.796
      objective function value: 2.08155
      classification error rate: 0.4
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 48 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353427
      gradient-norm: 57048.8
      step size: 335.432
      objective function value: 1.74497
      classification error rate: 0.272727
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 49 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353442
      gradient-norm: 63621.9
      step size: 330.779
      objective function value: 1.91532
      classification error rate: 0.309091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 50 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353458
      gradient-norm: 54402.6
      step size: 321.39
      objective function value: 1.68463
      classification error rate: 0.290909
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 51 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353473
      gradient-norm: 65948.6
      step size: 318.435
      objective function value: 1.88388
      classification error rate: 0.254545
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 52 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353488
      gradient-norm: 82739.9
      step size: 327.73
      objective function value: 2.25949
      classification error rate: 0.472727
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 53 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353502
      gradient-norm: 77501.7
      step size: 331.538
      objective function value: 2.22782
      classification error rate: 0.327273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 54 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353516
      gradient-norm: 56527.8
      step size: 323.389
      objective function value: 1.67986
      classification error rate: 0.236364
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 55 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353530
      gradient-norm: 73388.6
      step size: 326.4
      objective function value: 1.95684
      classification error rate: 0.290909
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 56 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353543
      gradient-norm: 65249.2
      step size: 323.576
      objective function value: 2.05464
      classification error rate: 0.345455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 57 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353557
      gradient-norm: 64756.8
      step size: 318.837
      objective function value: 1.89252
      classification error rate: 0.254545
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 58 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353570
      gradient-norm: 70729.9
      step size: 320.455
      objective function value: 1.98245
      classification error rate: 0.345455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 59 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353583
      gradient-norm: 65096.2
      step size: 319.297
      objective function value: 1.88398
      classification error rate: 0.309091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 60 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353596
      gradient-norm: 79335.2
      step size: 325.384
      objective function value: 1.99809
      classification error rate: 0.345455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 61 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353609
      gradient-norm: 77110.7
      step size: 325.833
      objective function value: 1.94006
      classification error rate: 0.363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 62 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353622
      gradient-norm: 87387.2
      step size: 339.824
      objective function value: 2.3808
      classification error rate: 0.490909
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 63 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353635
      gradient-norm: 64671
      step size: 335.09
      objective function value: 1.69585
      classification error rate: 0.272727
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 64 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353647
      gradient-norm: 53818.9
      step size: 323.5
      objective function value: 1.72601
      classification error rate: 0.254545
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 65 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353660
      gradient-norm: 71433
      step size: 318.172
      objective function value: 1.97618
      classification error rate: 0.309091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 66 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353673
      gradient-norm: 61169.2
      step size: 313.673
      objective function value: 1.80199
      classification error rate: 0.254545
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 67 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353685
      gradient-norm: 64757.5
      step size: 310.671
      objective function value: 1.89354
      classification error rate: 0.327273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 68 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353698
      gradient-norm: 59857.4
      step size: 307.195
      objective function value: 1.75764
      classification error rate: 0.272727
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 69 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353710
      gradient-norm: 53390.3
      step size: 297.996
      objective function value: 1.63628
      classification error rate: 0.236364
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 70 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353722
      gradient-norm: 42078.4
      step size: 286.012
      objective function value: 1.60491
      classification error rate: 0.2
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 71 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353733
      gradient-norm: 54223.1
      step size: 277.929
      objective function value: 1.72137
      classification error rate: 0.327273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 72 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353745
      gradient-norm: 51421.5
      step size: 273.158
      objective function value: 1.6911
      classification error rate: 0.254545
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 73 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353756
      gradient-norm: 52061.1
      step size: 269.715
      objective function value: 1.71426
      classification error rate: 0.254545
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 74 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353767
      gradient-norm: 52258.4
      step size: 268.259
      objective function value: 1.69373
      classification error rate: 0.218182
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 75 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353777
      gradient-norm: 54227.9
      step size: 266.485
      objective function value: 1.57573
      classification error rate: 0.2
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 76 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353788
      gradient-norm: 40577.4
      step size: 258.447
      objective function value: 1.52483
      classification error rate: 0.236364
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 77 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353798
      gradient-norm: 45801.8
      step size: 252.105
      objective function value: 1.39881
      classification error rate: 0.127273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 78 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353808
      gradient-norm: 39822.4
      step size: 243.887
      objective function value: 1.48025
      classification error rate: 0.2
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 79 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353818
      gradient-norm: 59570
      step size: 249.028
      objective function value: 1.65557
      classification error rate: 0.236364
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 80 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353827
      gradient-norm: 52717.4
      step size: 249.312
      objective function value: 1.64439
      classification error rate: 0.272727
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 81 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353836
      gradient-norm: 55821.2
      step size: 251.566
      objective function value: 1.60157
      classification error rate: 0.236364
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 82 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353846
      gradient-norm: 38435.9
      step size: 242.332
      objective function value: 1.39093
      classification error rate: 0.145455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 83 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353855
      gradient-norm: 45930.4
      step size: 239.493
      objective function value: 1.48226
      classification error rate: 0.127273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 84 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353864
      gradient-norm: 45204
      step size: 234.616
      objective function value: 1.45372
      classification error rate: 0.163636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 85 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353873
      gradient-norm: 55659
      step size: 240.104
      objective function value: 1.63954
      classification error rate: 0.236364
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 86 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353882
      gradient-norm: 37658.7
      step size: 232.913
      objective function value: 1.25135
      classification error rate: 0.0909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 87 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353890
      gradient-norm: 47408.3
      step size: 232.697
      objective function value: 1.42872
      classification error rate: 0.145455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 88 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353899
      gradient-norm: 50876.8
      step size: 232.098
      objective function value: 1.5912
      classification error rate: 0.218182
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 89 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353907
      gradient-norm: 32776.4
      step size: 222.954
      objective function value: 1.26373
      classification error rate: 0.127273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 90 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353916
      gradient-norm: 48426.7
      step size: 222.705
      objective function value: 1.50527
      classification error rate: 0.2
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 91 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353924
      gradient-norm: 55474.8
      step size: 228.572
      objective function value: 1.46131
      classification error rate: 0.181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 92 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353932
      gradient-norm: 36584
      step size: 222.172
      objective function value: 1.32445
      classification error rate: 0.145455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 93 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353940
      gradient-norm: 56198.9
      step size: 230.171
      objective function value: 1.55088
      classification error rate: 0.2
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 94 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353948
      gradient-norm: 46895
      step size: 228.43
      objective function value: 1.4025
      classification error rate: 0.163636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 95 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353956
      gradient-norm: 48356.5
      step size: 228.101
      objective function value: 1.351
      classification error rate: 0.0909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 96 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353964
      gradient-norm: 43342.9
      step size: 225.096
      objective function value: 1.30021
      classification error rate: 0.127273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 97 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353972
      gradient-norm: 25963.1
      step size: 213.275
      objective function value: 1.25809
      classification error rate: 0.0727273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 98 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353979
      gradient-norm: 39048.4
      step size: 208.984
      objective function value: 1.28172
      classification error rate: 0.109091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 99 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353987
      gradient-norm: 59458.9
      step size: 218.913
      objective function value: 1.64528
      classification error rate: 0.236364
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 100 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 353994
      gradient-norm: 29277.5
      step size: 209.069
      objective function value: 1.2325
      classification error rate: 0.0909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 101 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354002
      gradient-norm: 29742.3
      step size: 200.198
      objective function value: 1.1897
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 102 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354009
      gradient-norm: 44340.5
      step size: 200.838
      objective function value: 1.31654
      classification error rate: 0.127273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 103 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354016
      gradient-norm: 57302.6
      step size: 211.625
      objective function value: 1.53329
      classification error rate: 0.2
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 104 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354023
      gradient-norm: 34709.3
      step size: 206.577
      objective function value: 1.29788
      classification error rate: 0.127273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 105 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354030
      gradient-norm: 46178.5
      step size: 206.992
      objective function value: 1.40192
      classification error rate: 0.145455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 106 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354037
      gradient-norm: 54941.6
      step size: 213.24
      objective function value: 1.5216
      classification error rate: 0.218182
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 107 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354044
      gradient-norm: 34777.5
      step size: 207.216
      objective function value: 1.2512
      classification error rate: 0.109091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 108 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354051
      gradient-norm: 29738.1
      step size: 198.126
      objective function value: 1.11487
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 109 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354058
      gradient-norm: 51775.1
      step size: 204.848
      objective function value: 1.41308
      classification error rate: 0.145455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 110 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354065
      gradient-norm: 43573.8
      step size: 205.921
      objective function value: 1.27259
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 111 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354071
      gradient-norm: 43238.2
      step size: 202.829
      objective function value: 1.34605
      classification error rate: 0.145455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 112 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354078
      gradient-norm: 26825.3
      step size: 192.671
      objective function value: 1.09158
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 113 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354085
      gradient-norm: 46407.5
      step size: 197.396
      objective function value: 1.26918
      classification error rate: 0.127273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 114 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354092
      gradient-norm: 42154.3
      step size: 198.957
      objective function value: 1.274
      classification error rate: 0.109091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 115 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354099
      gradient-norm: 53852.2
      step size: 206.367
      objective function value: 1.35169
      classification error rate: 0.0727273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 116 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354105
      gradient-norm: 47421.1
      step size: 208.424
      objective function value: 1.38037
      classification error rate: 0.109091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 117 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354112
      gradient-norm: 40881.4
      step size: 207.625
      objective function value: 1.32676
      classification error rate: 0.163636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 118 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354119
      gradient-norm: 49747.3
      step size: 212.333
      objective function value: 1.29602
      classification error rate: 0.109091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 119 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354126
      gradient-norm: 38739.5
      step size: 208.684
      objective function value: 1.28371
      classification error rate: 0.127273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 120 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354133
      gradient-norm: 37859.3
      step size: 205.177
      objective function value: 1.31685
      classification error rate: 0.127273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 121 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354140
      gradient-norm: 49231.5
      step size: 203.696
      objective function value: 1.23521
      classification error rate: 0.127273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 122 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354147
      gradient-norm: 59000.3
      step size: 215.414
      objective function value: 1.57361
      classification error rate: 0.236364
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 123 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354154
      gradient-norm: 39147.2
      step size: 210.036
      objective function value: 1.2048
      classification error rate: 0.0909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 124 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354162
      gradient-norm: 30570.5
      step size: 200.638
      objective function value: 1.18741
      classification error rate: 0.109091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 125 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354169
      gradient-norm: 33530.1
      step size: 194.776
      objective function value: 1.21874
      classification error rate: 0.109091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 126 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354176
      gradient-norm: 40576
      step size: 195.079
      objective function value: 1.21977
      classification error rate: 0.145455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 127 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354183
      gradient-norm: 43280
      step size: 197.29
      objective function value: 1.23202
      classification error rate: 0.0909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 128 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354191
      gradient-norm: 43637.2
      step size: 196.757
      objective function value: 1.35522
      classification error rate: 0.109091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 129 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354198
      gradient-norm: 44140.8
      step size: 198.508
      objective function value: 1.21964
      classification error rate: 0.0909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 130 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354205
      gradient-norm: 42758.6
      step size: 200.246
      objective function value: 1.19699
      classification error rate: 0.0909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 131 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354212
      gradient-norm: 25712.3
      step size: 190.448
      objective function value: 1.12273
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 132 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354220
      gradient-norm: 38566.2
      step size: 188.173
      objective function value: 1.26433
      classification error rate: 0.0727273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 133 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354227
      gradient-norm: 24774.5
      step size: 180.843
      objective function value: 1.11573
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 134 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354234
      gradient-norm: 52495.1
      step size: 192.292
      objective function value: 1.36056
      classification error rate: 0.145455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 135 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354240
      gradient-norm: 24738.5
      step size: 181.786
      objective function value: 1.14467
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 136 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354247
      gradient-norm: 44504
      step size: 185.323
      objective function value: 1.32392
      classification error rate: 0.145455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 137 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354253
      gradient-norm: 38778.2
      step size: 184.067
      objective function value: 1.15918
      classification error rate: 0.0909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 138 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354260
      gradient-norm: 56967.8
      step size: 197.948
      objective function value: 1.39616
      classification error rate: 0.145455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 139 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354266
      gradient-norm: 39419.2
      step size: 197.238
      objective function value: 1.26736
      classification error rate: 0.109091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 140 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354272
      gradient-norm: 41093.9
      step size: 194.62
      objective function value: 1.22797
      classification error rate: 0.0909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 141 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354278
      gradient-norm: 25402.2
      step size: 185.563
      objective function value: 1.15251
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 142 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354285
      gradient-norm: 37691.5
      step size: 181.091
      objective function value: 1.22592
      classification error rate: 0.0909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 143 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354291
      gradient-norm: 27201.1
      step size: 173.955
      objective function value: 1.16057
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 144 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354297
      gradient-norm: 15439.6
      step size: 162.664
      objective function value: 1.06385
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 145 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354303
      gradient-norm: 32324.7
      step size: 159.204
      objective function value: 1.17337
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 146 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354309
      gradient-norm: 31909.3
      step size: 159.049
      objective function value: 1.24512
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 147 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354315
      gradient-norm: 49125.3
      step size: 166.893
      objective function value: 1.3169
      classification error rate: 0.145455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 148 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354320
      gradient-norm: 40848.1
      step size: 171.011
      objective function value: 1.19711
      classification error rate: 0.0909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 149 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354326
      gradient-norm: 22929.1
      step size: 162.522
      objective function value: 1.13017
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 150 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354331
      gradient-norm: 44333.7
      step size: 169.811
      objective function value: 1.33958
      classification error rate: 0.109091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 151 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354337
      gradient-norm: 41020.2
      step size: 174.469
      objective function value: 1.24944
      classification error rate: 0.109091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 152 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354342
      gradient-norm: 17179
      step size: 164.333
      objective function value: 1.08045
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 153 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354348
      gradient-norm: 22321
      step size: 157.505
      objective function value: 1.1808
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 154 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354353
      gradient-norm: 20274.9
      step size: 149.431
      objective function value: 1.08028
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 155 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354359
      gradient-norm: 49747.4
      step size: 161.353
      objective function value: 1.32048
      classification error rate: 0.127273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 156 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354364
      gradient-norm: 22549.4
      step size: 155.071
      objective function value: 1.09638
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 157 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354369
      gradient-norm: 29682.7
      step size: 152.74
      objective function value: 1.21737
      classification error rate: 0.0727273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 158 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354375
      gradient-norm: 40366.5
      step size: 155.716
      objective function value: 1.19278
      classification error rate: 0.109091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 159 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354380
      gradient-norm: 26209.6
      step size: 151.607
      objective function value: 1.17695
      classification error rate: 0.0727273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 160 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354385
      gradient-norm: 22266
      step size: 144.111
      objective function value: 1.10998
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 161 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354389
      gradient-norm: 17422.3
      step size: 135.564
      objective function value: 1.04682
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 162 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354394
      gradient-norm: 32162
      step size: 136.93
      objective function value: 1.19406
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 163 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354399
      gradient-norm: 37391.5
      step size: 140.893
      objective function value: 1.18481
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 164 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354403
      gradient-norm: 37180.7
      step size: 145.519
      objective function value: 1.17767
      classification error rate: 0.109091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 165 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354407
      gradient-norm: 32430.5
      step size: 145.691
      objective function value: 1.25696
      classification error rate: 0.0909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 166 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354411
      gradient-norm: 21537.1
      step size: 140.448
      objective function value: 1.07231
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 167 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354415
      gradient-norm: 42730.1
      step size: 146.866
      objective function value: 1.25406
      classification error rate: 0.109091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 168 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354420
      gradient-norm: 22244.3
      step size: 141.102
      objective function value: 1.12798
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 169 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354424
      gradient-norm: 16860.4
      step size: 134.19
      objective function value: 1.06177
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 170 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354428
      gradient-norm: 18119.4
      step size: 128.073
      objective function value: 1.03501
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 171 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354432
      gradient-norm: 44523.7
      step size: 140.762
      objective function value: 1.12985
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 172 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354436
      gradient-norm: 32431.2
      step size: 141.389
      objective function value: 1.107
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 173 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354440
      gradient-norm: 20162.7
      step size: 135.831
      objective function value: 1.08615
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 174 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354444
      gradient-norm: 24133.9
      step size: 132.453
      objective function value: 1.05413
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 175 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354448
      gradient-norm: 34934.2
      step size: 135.242
      objective function value: 1.18999
      classification error rate: 0.0727273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 176 with 5 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354452
      gradient-norm: 177.58
      step size: 121.787
      objective function value: 0.980059
      classification error rate: 0
    </neural-network.process-batch>
    Processed 9630 observations in 176 mini-batches.
  </neural-network.process-epoch>
  Start epoch 2
  <neural-network.process-epoch>
    <neural-network.process-batch>
      Process mini-batch 1 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354455
      gradient-norm: 29856.7
      step size: 122.536
      objective function value: 1.09121
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 2 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354459
      gradient-norm: 27103
      step size: 121.974
      objective function value: 1.16507
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 3 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354463
      gradient-norm: 29379.1
      step size: 124.343
      objective function value: 1.10046
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 4 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354466
      gradient-norm: 54805.5
      step size: 145.001
      objective function value: 1.33031
      classification error rate: 0.127273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 5 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354469
      gradient-norm: 33329.4
      step size: 147.403
      objective function value: 1.16136
      classification error rate: 0.0727273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 6 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354473
      gradient-norm: 28987.1
      step size: 145.256
      objective function value: 1.10332
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 7 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354477
      gradient-norm: 24396.9
      step size: 140.738
      objective function value: 1.09371
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 8 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354480
      gradient-norm: 12934.5
      step size: 131.252
      objective function value: 1.06871
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 9 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354484
      gradient-norm: 31289.7
      step size: 133.899
      objective function value: 1.09831
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 10 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354488
      gradient-norm: 14432.5
      step size: 125.905
      objective function value: 1.05239
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 11 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354492
      gradient-norm: 24559.3
      step size: 124.479
      objective function value: 1.12549
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 12 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354495
      gradient-norm: 17038.2
      step size: 118.253
      objective function value: 1.06599
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 13 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354499
      gradient-norm: 40775.4
      step size: 125.465
      objective function value: 1.17635
      classification error rate: 0.109091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 14 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354503
      gradient-norm: 34159.9
      step size: 130.129
      objective function value: 1.17137
      classification error rate: 0.0909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 15 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354506
      gradient-norm: 28554.3
      step size: 131.652
      objective function value: 1.16045
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 16 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354510
      gradient-norm: 9299.01
      step size: 121.425
      objective function value: 1.01251
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 17 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354513
      gradient-norm: 24549.4
      step size: 119.175
      objective function value: 1.1486
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 18 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354516
      gradient-norm: 34227
      step size: 125.667
      objective function value: 1.16062
      classification error rate: 0.0909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 19 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354520
      gradient-norm: 20139.3
      step size: 122.154
      objective function value: 1.15616
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 20 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354523
      gradient-norm: 13105.3
      step size: 114.961
      objective function value: 1.07119
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 21 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354526
      gradient-norm: 39319.3
      step size: 124.128
      objective function value: 1.21825
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 22 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354529
      gradient-norm: 15392.3
      step size: 117.669
      objective function value: 1.048
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 23 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354532
      gradient-norm: 19083.1
      step size: 114.892
      objective function value: 1.08148
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 24 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354535
      gradient-norm: 7943.42
      step size: 106.27
      objective function value: 1.00617
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 25 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354538
      gradient-norm: 40214.6
      step size: 119.304
      objective function value: 1.18821
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 26 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354541
      gradient-norm: 33457.9
      step size: 121.906
      objective function value: 1.17998
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 27 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354543
      gradient-norm: 17238.8
      step size: 115.458
      objective function value: 1.0845
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 28 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354546
      gradient-norm: 14319
      step size: 108.962
      objective function value: 1.08533
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 29 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354548
      gradient-norm: 14769.5
      step size: 103.047
      objective function value: 1.0401
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 30 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354551
      gradient-norm: 35924.9
      step size: 110.463
      objective function value: 1.0988
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 31 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354553
      gradient-norm: 41157.1
      step size: 121.381
      objective function value: 1.34803
      classification error rate: 0.0909091
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 32 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354556
      gradient-norm: 14883.3
      step size: 114.83
      objective function value: 1.03891
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 33 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354558
      gradient-norm: 33585
      step size: 123.218
      objective function value: 1.17991
      classification error rate: 0.0727273
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 34 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354561
      gradient-norm: 15439.2
      step size: 115.81
      objective function value: 1.02582
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 35 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354563
      gradient-norm: 23454.4
      step size: 114.77
      objective function value: 1.06191
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 36 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354566
      gradient-norm: 25011.2
      step size: 115.552
      objective function value: 1.07901
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 37 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354569
      gradient-norm: 29953
      step size: 118.264
      objective function value: 1.1018
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 38 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354572
      gradient-norm: 25735
      step size: 118.387
      objective function value: 1.11347
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 39 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354575
      gradient-norm: 37363.8
      step size: 124.463
      objective function value: 1.31227
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 40 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354578
      gradient-norm: 15270.6
      step size: 116.91
      objective function value: 1.04472
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 41 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354581
      gradient-norm: 11132.4
      step size: 109.513
      objective function value: 1.02114
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 42 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354584
      gradient-norm: 19137
      step size: 108.747
      objective function value: 1.05857
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 43 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354587
      gradient-norm: 10768.5
      step size: 102.01
      objective function value: 1.03493
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 44 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354589
      gradient-norm: 9580.29
      step size: 95.7806
      objective function value: 1.0202
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 45 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354592
      gradient-norm: 13234.2
      step size: 90.9706
      objective function value: 1.03606
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 46 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354594
      gradient-norm: 6051.92
      step size: 83.8303
      objective function value: 0.99915
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 47 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354597
      gradient-norm: 6066.32
      step size: 77.3822
      objective function value: 0.992526
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 48 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354599
      gradient-norm: 17575
      step size: 76.6902
      objective function value: 1.03004
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 49 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354601
      gradient-norm: 21501.6
      step size: 80.4231
      objective function value: 1.06847
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 50 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354603
      gradient-norm: 11448.4
      step size: 77.3556
      objective function value: 1.02182
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 51 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354604
      gradient-norm: 9096.9
      step size: 73.2458
      objective function value: 1.00843
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 52 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354606
      gradient-norm: 8905.21
      step size: 69.2531
      objective function value: 1.00691
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 53 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354607
      gradient-norm: 9493.3
      step size: 66.4559
      objective function value: 1.02112
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 54 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354609
      gradient-norm: 23964.1
      step size: 71.7116
      objective function value: 1.05287
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 55 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354610
      gradient-norm: 26857.3
      step size: 79.8455
      objective function value: 1.12381
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 56 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354611
      gradient-norm: 13965.8
      step size: 78.6702
      objective function value: 1.01102
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 57 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354612
      gradient-norm: 7769.67
      step size: 74.379
      objective function value: 1.00027
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 58 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354613
      gradient-norm: 9967.68
      step size: 70.7598
      objective function value: 1.02567
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 59 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354614
      gradient-norm: 12719.4
      step size: 69.0548
      objective function value: 1.04395
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 60 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354615
      gradient-norm: 21291
      step size: 72.2399
      objective function value: 1.08071
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 61 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354616
      gradient-norm: 13560.6
      step size: 71.5893
      objective function value: 1.03372
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 62 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354617
      gradient-norm: 8282.63
      step size: 67.3298
      objective function value: 1.01084
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 63 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354617
      gradient-norm: 10700
      step size: 65.344
      objective function value: 0.997941
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 64 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354618
      gradient-norm: 5583.56
      step size: 60.7028
      objective function value: 1.00246
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 65 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354619
      gradient-norm: 8337.1
      step size: 58.0556
      objective function value: 1.00924
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 66 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354619
      gradient-norm: 11472.9
      step size: 57.2637
      objective function value: 1.01541
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 67 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354620
      gradient-norm: 3419.55
      step size: 52.6422
      objective function value: 0.993793
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 68 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354620
      gradient-norm: 10177.8
      step size: 51.7534
      objective function value: 1.01845
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 69 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354620
      gradient-norm: 13238.1
      step size: 54.04
      objective function value: 1.04951
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 70 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354620
      gradient-norm: 32918.2
      step size: 71.1039
      objective function value: 1.11893
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 71 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354621
      gradient-norm: 19590.4
      step size: 73.8928
      objective function value: 1.05251
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 72 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354621
      gradient-norm: 1078.29
      step size: 66.8124
      objective function value: 0.982583
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 73 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354621
      gradient-norm: 22516.2
      step size: 72.4206
      objective function value: 1.1179
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 74 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354621
      gradient-norm: 9247.7
      step size: 69.3353
      objective function value: 1.01279
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 75 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354622
      gradient-norm: 12177.7
      step size: 67.7457
      objective function value: 1.00724
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 76 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354622
      gradient-norm: 14529.5
      step size: 67.5175
      objective function value: 1.03539
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 77 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354622
      gradient-norm: 15795
      step size: 66.8718
      objective function value: 1.03472
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 78 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354623
      gradient-norm: 23328.5
      step size: 73.8454
      objective function value: 1.01976
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 79 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354623
      gradient-norm: 18279
      step size: 74.9381
      objective function value: 1.08575
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 80 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354624
      gradient-norm: 11149.6
      step size: 71.9766
      objective function value: 1.00716
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 81 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354624
      gradient-norm: 3579.59
      step size: 65.6722
      objective function value: 0.989496
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 82 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354625
      gradient-norm: 4639.21
      step size: 60.7887
      objective function value: 0.995031
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 83 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354625
      gradient-norm: 18651.3
      step size: 63.5198
      objective function value: 1.05989
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 84 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 13481.5
      step size: 61.9197
      objective function value: 1.01924
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 85 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 23157.8
      step size: 68.5256
      objective function value: 1.03176
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 86 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 16767.8
      step size: 69.1549
      objective function value: 1.02817
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 87 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 3914.89
      step size: 63.3248
      objective function value: 0.98889
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 88 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 10516.1
      step size: 61.293
      objective function value: 1.0094
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 89 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 17843.4
      step size: 64.0087
      objective function value: 1.02425
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 90 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 2491.17
      step size: 58.1476
      objective function value: 0.985012
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 91 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 18223
      step size: 61.7662
      objective function value: 1.09096
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 92 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 3895
      step size: 56.9412
      objective function value: 0.991708
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 93 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 12223
      step size: 57.5816
      objective function value: 1.09729
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 94 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 11255.1
      step size: 56.4136
      objective function value: 1.02197
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 95 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 14587.8
      step size: 56.7979
      objective function value: 1.02409
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 96 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 8700.79
      step size: 54.7639
      objective function value: 1.00173
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 97 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 10399.4
      step size: 53.5716
      objective function value: 1.01561
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 98 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 4767.19
      step size: 50.0975
      objective function value: 0.991847
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 99 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 13829.5
      step size: 51.0064
      objective function value: 1.02667
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 100 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 685.478
      step size: 46.1177
      objective function value: 0.981146
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 101 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 10904.8
      step size: 47.4127
      objective function value: 1.03411
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 102 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 1541.51
      step size: 43.1659
      objective function value: 0.983757
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 103 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 19994.5
      step size: 50.3825
      objective function value: 1.05392
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 104 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 9005.29
      step size: 48.684
      objective function value: 0.999186
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 105 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 3886.58
      step size: 45.2202
      objective function value: 0.995971
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 106 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 7678.55
      step size: 44.0838
      objective function value: 1.0024
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 107 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 10560.2
      step size: 44.9132
      objective function value: 1.03286
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 108 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 8770.28
      step size: 44.2826
      objective function value: 1.0047
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 109 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 14321.1
      step size: 48.1275
      objective function value: 1.0294
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 110 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 12797.6
      step size: 49.6703
      objective function value: 1.00306
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 111 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 12358.7
      step size: 51.5422
      objective function value: 1.04056
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 112 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 17889.7
      step size: 55.8366
      objective function value: 1.03944
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 113 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 32867.5
      step size: 72.6362
      objective function value: 1.13357
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 114 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 35241.3
      step size: 88.2216
      objective function value: 1.14194
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 115 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 22085.2
      step size: 91.095
      objective function value: 1.02669
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 116 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 15249.5
      step size: 89.5868
      objective function value: 1.04792
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 117 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 24415.9
      step size: 91.7557
      objective function value: 1.05368
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 118 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354634
      gradient-norm: 1908.24
      step size: 83.2089
      objective function value: 0.984968
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 119 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354636
      gradient-norm: 13084.2
      step size: 80.8299
      objective function value: 1.03448
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 120 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354638
      gradient-norm: 4314.28
      step size: 74.3604
      objective function value: 0.98508
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 121 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354641
      gradient-norm: 26773.4
      step size: 79.9814
      objective function value: 1.07748
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 122 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354643
      gradient-norm: 10792.5
      step size: 75.6292
      objective function value: 1.00241
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 123 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354645
      gradient-norm: 1084.73
      step size: 68.4475
      objective function value: 0.982848
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 124 with 55 observations.
      Iteration 300: Reduce learning rate to 0.0001
      parameter-norm (l1-norm of all trainable weights and biases): 354647
      gradient-norm: 18256.9
      step size: 61.9874
      objective function value: 1.04274
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 125 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354649
      gradient-norm: 34250.8
      step size: 57.0507
      objective function value: 1.12646
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 126 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354651
      gradient-norm: 16838.2
      step size: 51.8027
      objective function value: 1.02379
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 127 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354653
      gradient-norm: 12064.1
      step size: 47.0801
      objective function value: 1.00649
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 128 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354655
      gradient-norm: 12636.3
      step size: 42.8272
      objective function value: 1.00892
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 129 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354657
      gradient-norm: 40957.3
      step size: 40.281
      objective function value: 1.15134
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 130 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354659
      gradient-norm: 19351
      step size: 36.8624
      objective function value: 1.03668
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 131 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354660
      gradient-norm: 32582.1
      step size: 34.2525
      objective function value: 1.14314
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 132 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354662
      gradient-norm: 23829.9
      step size: 31.5922
      objective function value: 1.10684
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 133 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354663
      gradient-norm: 8461.14
      step size: 28.6655
      objective function value: 1.01007
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 134 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354665
      gradient-norm: 4027.23
      step size: 25.9447
      objective function value: 0.989391
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 135 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354666
      gradient-norm: 19996
      step size: 24.1872
      objective function value: 1.09728
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 136 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354667
      gradient-norm: 19319.5
      step size: 22.3646
      objective function value: 1.06575
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 137 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354668
      gradient-norm: 5826.09
      step size: 20.1862
      objective function value: 0.987125
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 138 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354668
      gradient-norm: 24405.7
      step size: 18.9917
      objective function value: 1.11392
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 139 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354669
      gradient-norm: 1092.49
      step size: 17.1224
      objective function value: 0.981526
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 140 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354670
      gradient-norm: 5607.42
      step size: 15.5566
      objective function value: 0.990076
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 141 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354670
      gradient-norm: 22093
      step size: 15.0051
      objective function value: 1.04695
      classification error rate: 0.0545455
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 142 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354671
      gradient-norm: 15400.8
      step size: 14.1847
      objective function value: 1.01213
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 143 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354671
      gradient-norm: 23532.4
      step size: 13.6913
      objective function value: 1.08858
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 144 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354672
      gradient-norm: 21802.9
      step size: 13.2147
      objective function value: 1.0505
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 145 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354672
      gradient-norm: 6440.29
      step size: 12.0735
      objective function value: 0.989949
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 146 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354672
      gradient-norm: 17490.9
      step size: 11.5309
      objective function value: 1.06912
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 147 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354673
      gradient-norm: 15971.1
      step size: 11.0712
      objective function value: 1.06725
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 148 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354673
      gradient-norm: 9679.2
      step size: 10.3409
      objective function value: 1.01209
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 149 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354673
      gradient-norm: 9837.79
      step size: 9.64597
      objective function value: 0.999486
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 150 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354673
      gradient-norm: 10385.4
      step size: 9.08859
      objective function value: 1.0039
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 151 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354673
      gradient-norm: 2257.32
      step size: 8.25386
      objective function value: 0.984771
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 152 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354674
      gradient-norm: 4007.09
      step size: 7.56958
      objective function value: 0.988304
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 153 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354674
      gradient-norm: 12095.4
      step size: 7.36894
      objective function value: 1.02508
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 154 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354674
      gradient-norm: 4699.12
      step size: 6.83106
      objective function value: 0.991989
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 155 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354674
      gradient-norm: 14811.8
      step size: 6.8394
      objective function value: 1.01787
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 156 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354674
      gradient-norm: 5564.3
      step size: 6.33621
      objective function value: 0.99233
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 157 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354674
      gradient-norm: 3532.89
      step size: 5.81902
      objective function value: 0.988948
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 158 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354674
      gradient-norm: 10250.3
      step size: 5.75321
      objective function value: 1.01005
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 159 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354674
      gradient-norm: 11047
      step size: 5.68855
      objective function value: 1.01425
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 160 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354674
      gradient-norm: 14148.3
      step size: 5.88064
      objective function value: 1.02363
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 161 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354674
      gradient-norm: 16292.5
      step size: 6.143
      objective function value: 1.00425
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 162 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354674
      gradient-norm: 7387.4
      step size: 5.86321
      objective function value: 1.02989
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 163 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354673
      gradient-norm: 5152.72
      step size: 5.4629
      objective function value: 0.988974
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 164 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354673
      gradient-norm: 6798.68
      step size: 5.20827
      objective function value: 0.998456
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 165 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354673
      gradient-norm: 6760.83
      step size: 5.01597
      objective function value: 1.00446
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 166 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354673
      gradient-norm: 4440.85
      step size: 4.71015
      objective function value: 0.99113
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 167 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354673
      gradient-norm: 4789.33
      step size: 4.45485
      objective function value: 0.993707
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 168 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354673
      gradient-norm: 2199.53
      step size: 4.0914
      objective function value: 0.984346
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 169 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354673
      gradient-norm: 459.314
      step size: 3.70204
      objective function value: 0.980568
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 170 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354673
      gradient-norm: 2377.22
      step size: 3.42358
      objective function value: 0.984682
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 171 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354673
      gradient-norm: 466.126
      step size: 3.10203
      objective function value: 0.980593
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 172 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354673
      gradient-norm: 10270.8
      step size: 3.40976
      objective function value: 1.0086
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 173 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354672
      gradient-norm: 22883.9
      step size: 4.71131
      objective function value: 1.03926
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 174 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354672
      gradient-norm: 3249.43
      step size: 4.36136
      objective function value: 0.985955
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 175 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354672
      gradient-norm: 2587.45
      step size: 4.02038
      objective function value: 0.983692
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 176 with 5 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354672
      gradient-norm: 177.336
      step size: 3.62822
      objective function value: 0.979949
      classification error rate: 0
    </neural-network.process-batch>
    Processed 9630 observations in 176 mini-batches.
  </neural-network.process-epoch>
  Start epoch 3
  <neural-network.process-epoch>
    <neural-network.process-batch>
      Process mini-batch 1 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354672
      gradient-norm: 8849.91
      step size: 3.75208
      objective function value: 1.00433
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 2 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354672
      gradient-norm: 5620.61
      step size: 3.66801
      objective function value: 0.99495
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 3 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354672
      gradient-norm: 866.937
      step size: 3.33898
      objective function value: 0.981513
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 4 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354671
      gradient-norm: 1222.92
      step size: 3.04853
      objective function value: 0.982119
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 5 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354671
      gradient-norm: 6183.47
      step size: 3.00152
      objective function value: 0.991927
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 6 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354671
      gradient-norm: 9564.72
      step size: 3.14459
      objective function value: 1.00254
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 7 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354671
      gradient-norm: 4135.5
      step size: 3.03814
      objective function value: 0.991712
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 8 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354671
      gradient-norm: 15466.1
      step size: 3.68666
      objective function value: 1.04123
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 9 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354671
      gradient-norm: 432.985
      step size: 3.3375
      objective function value: 0.980657
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 10 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354671
      gradient-norm: 12239.1
      step size: 3.75645
      objective function value: 1.01233
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 11 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354670
      gradient-norm: 10183
      step size: 3.78076
      objective function value: 1.00136
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 12 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354670
      gradient-norm: 10435.7
      step size: 4.00937
      objective function value: 1.00828
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 13 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354670
      gradient-norm: 9400.29
      step size: 3.99114
      objective function value: 0.993967
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 14 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354670
      gradient-norm: 6659.66
      step size: 3.91107
      objective function value: 1.00227
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 15 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354670
      gradient-norm: 14652.9
      step size: 4.34041
      objective function value: 1.03817
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 16 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354670
      gradient-norm: 9618.43
      step size: 4.30897
      objective function value: 0.990133
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 17 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354670
      gradient-norm: 20103.2
      step size: 5.19529
      objective function value: 1.09135
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 18 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354669
      gradient-norm: 15317.1
      step size: 5.42949
      objective function value: 1.02457
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 19 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354669
      gradient-norm: 3320.8
      step size: 5.01644
      objective function value: 0.988727
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 20 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354669
      gradient-norm: 5125.57
      step size: 4.74778
      objective function value: 0.995826
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 21 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354669
      gradient-norm: 17311.7
      step size: 5.41696
      objective function value: 1.01499
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 22 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354669
      gradient-norm: 4949.44
      step size: 5.11514
      objective function value: 0.989182
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 23 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354668
      gradient-norm: 2334.73
      step size: 4.67743
      objective function value: 0.98615
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 24 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354668
      gradient-norm: 1322.98
      step size: 4.26432
      objective function value: 0.982602
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 25 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354668
      gradient-norm: 14399.4
      step size: 4.59919
      objective function value: 1.02391
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 26 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354668
      gradient-norm: 4240.01
      step size: 4.30637
      objective function value: 0.992359
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 27 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354668
      gradient-norm: 11909.3
      step size: 4.52896
      objective function value: 1.02678
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 28 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354668
      gradient-norm: 859.222
      step size: 4.11057
      objective function value: 0.982064
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 29 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354668
      gradient-norm: 21356.5
      step size: 5.02414
      objective function value: 1.06772
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 30 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354668
      gradient-norm: 4253.92
      step size: 4.66917
      objective function value: 0.991969
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 31 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354667
      gradient-norm: 18851.7
      step size: 5.33507
      objective function value: 1.04643
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 32 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354667
      gradient-norm: 11601.9
      step size: 5.42021
      objective function value: 1.02242
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 33 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354667
      gradient-norm: 2885.45
      step size: 4.96794
      objective function value: 0.987085
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 34 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354667
      gradient-norm: 3973.28
      step size: 4.63614
      objective function value: 0.988869
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 35 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354667
      gradient-norm: 16484.1
      step size: 5.1122
      objective function value: 1.01351
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 36 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354667
      gradient-norm: 1204.91
      step size: 4.65629
      objective function value: 0.983029
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 37 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354666
      gradient-norm: 6079.02
      step size: 4.47584
      objective function value: 0.995586
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 38 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354666
      gradient-norm: 6850.67
      step size: 4.37516
      objective function value: 1.01038
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 39 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354666
      gradient-norm: 11847.5
      step size: 4.5426
      objective function value: 1.01885
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 40 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354666
      gradient-norm: 6858.98
      step size: 4.39814
      objective function value: 0.997654
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 41 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354666
      gradient-norm: 2992.76
      step size: 4.08137
      objective function value: 0.985723
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 42 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354666
      gradient-norm: 8023.29
      step size: 4.12692
      objective function value: 0.99636
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 43 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354666
      gradient-norm: 5818.05
      step size: 3.9775
      objective function value: 0.998193
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 44 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354666
      gradient-norm: 14713
      step size: 4.4308
      objective function value: 1.02168
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 45 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354665
      gradient-norm: 36303.4
      step size: 6.50348
      objective function value: 1.25443
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 46 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354665
      gradient-norm: 1221.42
      step size: 5.89285
      objective function value: 0.982416
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 47 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354665
      gradient-norm: 2874.69
      step size: 5.3955
      objective function value: 0.985001
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 48 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354665
      gradient-norm: 4180.56
      step size: 5.02419
      objective function value: 0.990771
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 49 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354665
      gradient-norm: 13448
      step size: 5.24513
      objective function value: 1.03665
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 50 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354665
      gradient-norm: 8436.63
      step size: 5.1263
      objective function value: 1.01167
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 51 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354664
      gradient-norm: 8036.34
      step size: 4.96891
      objective function value: 0.997979
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 52 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354664
      gradient-norm: 8326.24
      step size: 4.8801
      objective function value: 1.00848
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 53 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354664
      gradient-norm: 4457.11
      step size: 4.51828
      objective function value: 0.992848
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 54 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354664
      gradient-norm: 5283.02
      step size: 4.25266
      objective function value: 0.990765
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 55 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354664
      gradient-norm: 17432.4
      step size: 4.81152
      objective function value: 1.05992
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 56 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354664
      gradient-norm: 13232.1
      step size: 4.95139
      objective function value: 1.0425
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 57 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354663
      gradient-norm: 5004.57
      step size: 4.69252
      objective function value: 0.999226
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 58 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354663
      gradient-norm: 11754.6
      step size: 4.81459
      objective function value: 1.01034
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 59 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354663
      gradient-norm: 641.478
      step size: 4.3569
      objective function value: 0.981379
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 60 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354663
      gradient-norm: 12498
      step size: 4.59012
      objective function value: 1.02257
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 61 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354663
      gradient-norm: 3281.45
      step size: 4.25322
      objective function value: 0.984376
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 62 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354663
      gradient-norm: 10334.9
      step size: 4.31924
      objective function value: 1.04453
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 63 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354662
      gradient-norm: 3456.11
      step size: 4.03301
      objective function value: 0.990129
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 64 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354662
      gradient-norm: 7849.65
      step size: 4.01049
      objective function value: 0.993827
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 65 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354662
      gradient-norm: 7285.57
      step size: 3.98338
      objective function value: 1.00842
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 66 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354662
      gradient-norm: 18125.3
      step size: 4.71492
      objective function value: 1.01653
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 67 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354662
      gradient-norm: 6095.36
      step size: 4.52368
      objective function value: 0.996703
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 68 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354662
      gradient-norm: 6071.85
      step size: 4.28669
      objective function value: 0.989525
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 69 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354661
      gradient-norm: 3412.63
      step size: 3.98734
      objective function value: 0.993995
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 70 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354661
      gradient-norm: 1168.96
      step size: 3.61493
      objective function value: 0.982174
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 71 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354661
      gradient-norm: 1980.79
      step size: 3.33036
      objective function value: 0.983208
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 72 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354661
      gradient-norm: 3188.21
      step size: 3.10823
      objective function value: 0.985695
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 73 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354661
      gradient-norm: 1568.86
      step size: 2.84736
      objective function value: 0.982756
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 74 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354661
      gradient-norm: 12751.8
      step size: 3.31927
      objective function value: 1.00936
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 75 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354660
      gradient-norm: 2989.99
      step size: 3.10186
      objective function value: 0.985699
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 76 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354660
      gradient-norm: 658.042
      step size: 2.81394
      objective function value: 0.981333
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 77 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354660
      gradient-norm: 3188.56
      step size: 2.67205
      objective function value: 0.990305
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 78 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354660
      gradient-norm: 10524.3
      step size: 2.97703
      objective function value: 1.00537
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 79 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354660
      gradient-norm: 11687
      step size: 3.2924
      objective function value: 1.01225
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 80 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354660
      gradient-norm: 1945.04
      step size: 3.04241
      objective function value: 0.983248
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 81 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354660
      gradient-norm: 8713.43
      step size: 3.17478
      objective function value: 0.998415
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 82 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354659
      gradient-norm: 8189.23
      step size: 3.2774
      objective function value: 1.00771
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 83 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354659
      gradient-norm: 13562
      step size: 3.69007
      objective function value: 1.01408
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 84 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354659
      gradient-norm: 431.082
      step size: 3.34023
      objective function value: 0.980609
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 85 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354659
      gradient-norm: 3675.98
      step size: 3.16156
      objective function value: 0.987835
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 86 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354659
      gradient-norm: 5476.93
      step size: 3.06488
      objective function value: 0.993486
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 87 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354659
      gradient-norm: 1292.33
      step size: 2.80069
      objective function value: 0.981808
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 88 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354658
      gradient-norm: 5584.96
      step size: 2.79083
      objective function value: 0.993974
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 89 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354658
      gradient-norm: 1862.12
      step size: 2.56022
      objective function value: 0.983013
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 90 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354658
      gradient-norm: 1576.8
      step size: 2.36966
      objective function value: 0.983718
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 91 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354658
      gradient-norm: 2299.72
      step size: 2.21768
      objective function value: 0.984506
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 92 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354658
      gradient-norm: 9326.57
      step size: 2.57537
      objective function value: 0.993492
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 93 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354658
      gradient-norm: 8304.87
      step size: 2.75703
      objective function value: 1.00896
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 94 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354657
      gradient-norm: 9933.05
      step size: 2.95101
      objective function value: 0.996853
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 95 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354657
      gradient-norm: 3284.86
      step size: 2.79967
      objective function value: 0.989477
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 96 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354657
      gradient-norm: 1420.34
      step size: 2.58368
      objective function value: 0.983051
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 97 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354657
      gradient-norm: 3529.58
      step size: 2.47426
      objective function value: 0.987682
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 98 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354657
      gradient-norm: 6258.89
      step size: 2.55267
      objective function value: 0.993046
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 99 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354657
      gradient-norm: 1253.5
      step size: 2.35513
      objective function value: 0.982584
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 100 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354656
      gradient-norm: 2578.16
      step size: 2.22417
      objective function value: 0.983971
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 101 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354656
      gradient-norm: 1961.63
      step size: 2.08841
      objective function value: 0.986761
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 102 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354656
      gradient-norm: 1333.18
      step size: 1.93598
      objective function value: 0.983141
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 103 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354656
      gradient-norm: 3579.69
      step size: 1.91229
      objective function value: 0.99215
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 104 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354656
      gradient-norm: 2635.68
      step size: 1.84136
      objective function value: 0.987637
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 105 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354656
      gradient-norm: 634.913
      step size: 1.68568
      objective function value: 0.981602
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 106 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354655
      gradient-norm: 2471.24
      step size: 1.64653
      objective function value: 0.986453
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 107 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354655
      gradient-norm: 6818.05
      step size: 1.9077
      objective function value: 0.99525
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 108 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354655
      gradient-norm: 9129.89
      step size: 2.33786
      objective function value: 1.00023
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 109 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354655
      gradient-norm: 2891.87
      step size: 2.21489
      objective function value: 0.986074
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 110 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354655
      gradient-norm: 10662.6
      step size: 2.62555
      objective function value: 0.997418
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 111 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354655
      gradient-norm: 7927.33
      step size: 2.82174
      objective function value: 0.999548
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 112 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354655
      gradient-norm: 7572.56
      step size: 2.90313
      objective function value: 0.993687
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 113 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354654
      gradient-norm: 5750.28
      step size: 2.90828
      objective function value: 0.994567
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 114 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354654
      gradient-norm: 2862.16
      step size: 2.74874
      objective function value: 0.988841
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 115 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354654
      gradient-norm: 2015.26
      step size: 2.57545
      objective function value: 0.983225
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 116 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354654
      gradient-norm: 6931.4
      step size: 2.68172
      objective function value: 1.0035
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 117 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354654
      gradient-norm: 6813.88
      step size: 2.76503
      objective function value: 0.993428
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 118 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354654
      gradient-norm: 1029.95
      step size: 2.52593
      objective function value: 0.981454
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 119 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354653
      gradient-norm: 2193.83
      step size: 2.37486
      objective function value: 0.987449
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 120 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354653
      gradient-norm: 6118.97
      step size: 2.4349
      objective function value: 0.990609
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 121 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354653
      gradient-norm: 18295.7
      step size: 3.48216
      objective function value: 1.01064
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 122 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354653
      gradient-norm: 13777.2
      step size: 3.86335
      objective function value: 1.03494
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 123 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354653
      gradient-norm: 17062.2
      step size: 4.46687
      objective function value: 1.04552
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 124 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354653
      gradient-norm: 8953.43
      step size: 4.40708
      objective function value: 1.00609
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 125 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354652
      gradient-norm: 15707.6
      step size: 4.84044
      objective function value: 1.03011
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 126 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354652
      gradient-norm: 1736.39
      step size: 4.39209
      objective function value: 0.982737
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 127 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354652
      gradient-norm: 3370.84
      step size: 4.07702
      objective function value: 0.989921
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 128 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354652
      gradient-norm: 4689.82
      step size: 3.83164
      objective function value: 0.988094
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 129 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354652
      gradient-norm: 7095.08
      step size: 3.79106
      objective function value: 1.00563
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 130 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354652
      gradient-norm: 9654.81
      step size: 3.96435
      objective function value: 0.996794
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 131 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354652
      gradient-norm: 1835.65
      step size: 3.64258
      objective function value: 0.983869
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 132 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354651
      gradient-norm: 1462.23
      step size: 3.33601
      objective function value: 0.983544
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 133 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354651
      gradient-norm: 10327
      step size: 3.61272
      objective function value: 1.01016
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 134 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354651
      gradient-norm: 1763.87
      step size: 3.31978
      objective function value: 0.983259
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 135 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354651
      gradient-norm: 5702.25
      step size: 3.17393
      objective function value: 0.992851
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 136 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354651
      gradient-norm: 905.835
      step size: 2.89056
      objective function value: 0.982054
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 137 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354651
      gradient-norm: 10495.6
      step size: 3.15213
      objective function value: 1.00309
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 138 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354650
      gradient-norm: 2140.38
      step size: 2.91528
      objective function value: 0.986476
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 139 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354650
      gradient-norm: 5327.75
      step size: 2.83824
      objective function value: 0.988792
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 140 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354650
      gradient-norm: 767.089
      step size: 2.58612
      objective function value: 0.981482
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 141 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354650
      gradient-norm: 2206.08
      step size: 2.43333
      objective function value: 0.983279
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 142 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354650
      gradient-norm: 8265.03
      step size: 2.57414
      objective function value: 0.995354
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 143 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354650
      gradient-norm: 7264.65
      step size: 2.70404
      objective function value: 1.00217
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 144 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354649
      gradient-norm: 409.482
      step size: 2.45292
      objective function value: 0.980657
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 145 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354649
      gradient-norm: 13780.9
      step size: 3.17762
      objective function value: 1.00869
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 146 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354649
      gradient-norm: 1041.41
      step size: 2.9011
      objective function value: 0.981661
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 147 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354649
      gradient-norm: 3235.22
      step size: 2.73104
      objective function value: 0.986242
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 148 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354649
      gradient-norm: 11668.6
      step size: 3.18527
      objective function value: 1.02771
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 149 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354649
      gradient-norm: 8018.85
      step size: 3.26911
      objective function value: 0.992469
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 150 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354648
      gradient-norm: 20610.4
      step size: 4.35484
      objective function value: 1.07952
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 151 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354648
      gradient-norm: 546.92
      step size: 3.94252
      objective function value: 0.981142
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 152 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354648
      gradient-norm: 530.608
      step size: 3.56565
      objective function value: 0.980432
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 153 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354648
      gradient-norm: 1317.79
      step size: 3.26595
      objective function value: 0.981979
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 154 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354648
      gradient-norm: 1837.26
      step size: 3.01226
      objective function value: 0.983039
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 155 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354648
      gradient-norm: 1748.34
      step size: 2.7876
      objective function value: 0.982667
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 156 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354648
      gradient-norm: 1781.93
      step size: 2.57416
      objective function value: 0.983605
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 157 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354647
      gradient-norm: 2595.42
      step size: 2.44989
      objective function value: 0.987853
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 158 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354647
      gradient-norm: 10955.5
      step size: 2.87163
      objective function value: 1.01629
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 159 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354647
      gradient-norm: 7783.64
      step size: 2.94887
      objective function value: 0.998849
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 160 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354647
      gradient-norm: 2748.59
      step size: 2.76248
      objective function value: 0.987086
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 161 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354647
      gradient-norm: 16494.5
      step size: 3.57933
      objective function value: 1.02953
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 162 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354646
      gradient-norm: 5684.81
      step size: 3.47619
      objective function value: 1.00427
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 163 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354646
      gradient-norm: 1007.71
      step size: 3.16958
      objective function value: 0.982188
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 164 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354646
      gradient-norm: 8838.06
      step size: 3.30796
      objective function value: 1.00565
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 165 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354646
      gradient-norm: 1887.96
      step size: 3.03297
      objective function value: 0.98394
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 166 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354646
      gradient-norm: 1206.73
      step size: 2.76355
      objective function value: 0.982059
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 167 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354646
      gradient-norm: 1491.57
      step size: 2.54486
      objective function value: 0.982836
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 168 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354646
      gradient-norm: 12065.8
      step size: 3.04906
      objective function value: 1.0101
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 169 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354645
      gradient-norm: 7261.02
      step size: 3.08028
      objective function value: 1.00473
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 170 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354645
      gradient-norm: 5916.37
      step size: 3.06702
      objective function value: 0.994995
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 171 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354645
      gradient-norm: 1705.06
      step size: 2.82132
      objective function value: 0.982404
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 172 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354645
      gradient-norm: 1948.18
      step size: 2.61275
      objective function value: 0.982867
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 173 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354645
      gradient-norm: 4211.94
      step size: 2.53367
      objective function value: 0.992243
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 174 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354645
      gradient-norm: 1698.03
      step size: 2.33334
      objective function value: 0.98188
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 175 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354644
      gradient-norm: 14547.4
      step size: 3.0471
      objective function value: 1.02774
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 176 with 5 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354644
      gradient-norm: 412.285
      step size: 2.75994
      objective function value: 0.980505
      classification error rate: 0
    </neural-network.process-batch>
    Processed 9630 observations in 176 mini-batches.
  </neural-network.process-epoch>
  Start epoch 4
  <neural-network.process-epoch>
    <neural-network.process-batch>
      Process mini-batch 1 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354644
      gradient-norm: 1413.34
      step size: 2.53127
      objective function value: 0.982515
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 2 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354644
      gradient-norm: 749.942
      step size: 2.31227
      objective function value: 0.981571
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 3 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354644
      gradient-norm: 1210.13
      step size: 2.12807
      objective function value: 0.983006
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 4 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354644
      gradient-norm: 7257.22
      step size: 2.32972
      objective function value: 0.996135
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 5 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354643
      gradient-norm: 8857.52
      step size: 2.63357
      objective function value: 0.998734
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 6 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354643
      gradient-norm: 4788.52
      step size: 2.58114
      objective function value: 0.999255
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 7 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354643
      gradient-norm: 9546.69
      step size: 2.92497
      objective function value: 1.01713
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 8 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354643
      gradient-norm: 4692.43
      step size: 2.85652
      objective function value: 0.987737
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 9 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354643
      gradient-norm: 8151.5
      step size: 2.98197
      objective function value: 1.01635
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 10 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354643
      gradient-norm: 11567.2
      step size: 3.32139
      objective function value: 1.02932
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 11 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354642
      gradient-norm: 10726.9
      step size: 3.58657
      objective function value: 1.01514
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 12 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354642
      gradient-norm: 2132.37
      step size: 3.31051
      objective function value: 0.983623
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 13 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354642
      gradient-norm: 13778.8
      step size: 3.82757
      objective function value: 1.01593
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 14 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354642
      gradient-norm: 1753.08
      step size: 3.51248
      objective function value: 0.98304
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 15 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354642
      gradient-norm: 2812.74
      step size: 3.22893
      objective function value: 0.988052
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 16 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354642
      gradient-norm: 988.928
      step size: 2.94196
      objective function value: 0.982386
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 17 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354641
      gradient-norm: 2043.92
      step size: 2.72017
      objective function value: 0.983736
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 18 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354641
      gradient-norm: 688
      step size: 2.47103
      objective function value: 0.980645
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 19 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354641
      gradient-norm: 4094.17
      step size: 2.43076
      objective function value: 0.988355
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 20 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354641
      gradient-norm: 2926.37
      step size: 2.31957
      objective function value: 0.986326
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 21 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354641
      gradient-norm: 8652.95
      step size: 2.5891
      objective function value: 1.00624
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 22 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354641
      gradient-norm: 5640.96
      step size: 2.64397
      objective function value: 0.990189
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 23 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354640
      gradient-norm: 2585.47
      step size: 2.43893
      objective function value: 0.983258
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 24 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354640
      gradient-norm: 598.324
      step size: 2.2172
      objective function value: 0.980764
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 25 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354640
      gradient-norm: 3630.08
      step size: 2.17763
      objective function value: 0.986702
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 26 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354640
      gradient-norm: 10398
      step size: 2.57333
      objective function value: 1.02056
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 27 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354640
      gradient-norm: 1443.13
      step size: 2.36455
      objective function value: 0.982757
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 28 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354640
      gradient-norm: 3642.44
      step size: 2.27148
      objective function value: 0.988448
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 29 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354640
      gradient-norm: 3243.81
      step size: 2.17523
      objective function value: 0.985364
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 30 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354639
      gradient-norm: 825.532
      step size: 1.99428
      objective function value: 0.981072
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 31 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354639
      gradient-norm: 6272.8
      step size: 2.11574
      objective function value: 0.991874
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 32 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354639
      gradient-norm: 1338.55
      step size: 1.9604
      objective function value: 0.981966
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 33 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354639
      gradient-norm: 2100.64
      step size: 1.85718
      objective function value: 0.984214
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 34 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354639
      gradient-norm: 3842.66
      step size: 1.86584
      objective function value: 0.990467
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 35 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354638
      gradient-norm: 6092.62
      step size: 2.0141
      objective function value: 0.998556
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 36 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354638
      gradient-norm: 1695.5
      step size: 1.89007
      objective function value: 0.983087
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 37 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354638
      gradient-norm: 1116.94
      step size: 1.74953
      objective function value: 0.981482
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 38 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354638
      gradient-norm: 5059.72
      step size: 1.82704
      objective function value: 0.98822
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 39 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354638
      gradient-norm: 400.06
      step size: 1.66345
      objective function value: 0.980391
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 40 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354638
      gradient-norm: 5243.55
      step size: 1.79967
      objective function value: 1.00627
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 41 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354638
      gradient-norm: 538.365
      step size: 1.64419
      objective function value: 0.980695
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 42 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354637
      gradient-norm: 1439.13
      step size: 1.54457
      objective function value: 0.9829
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 43 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354637
      gradient-norm: 589.69
      step size: 1.42011
      objective function value: 0.980708
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 44 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354637
      gradient-norm: 2207.71
      step size: 1.36914
      objective function value: 0.985101
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 45 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354637
      gradient-norm: 4253.07
      step size: 1.476
      objective function value: 0.987059
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 46 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354637
      gradient-norm: 1724.37
      step size: 1.40164
      objective function value: 0.984669
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 47 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354636
      gradient-norm: 429.665
      step size: 1.28467
      objective function value: 0.980293
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 48 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354636
      gradient-norm: 1073.67
      step size: 1.19301
      objective function value: 0.982361
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 49 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354636
      gradient-norm: 1177.94
      step size: 1.13275
      objective function value: 0.981997
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 50 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354636
      gradient-norm: 3879.02
      step size: 1.24533
      objective function value: 0.988166
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 51 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354636
      gradient-norm: 1115.71
      step size: 1.16103
      objective function value: 0.981411
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 52 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354636
      gradient-norm: 2350.42
      step size: 1.17187
      objective function value: 0.984595
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 53 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354635
      gradient-norm: 4744.05
      step size: 1.34786
      objective function value: 0.997504
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 54 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354635
      gradient-norm: 7257.95
      step size: 1.70227
      objective function value: 1.00536
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 55 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354635
      gradient-norm: 8957.91
      step size: 2.15244
      objective function value: 1.0055
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 56 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354635
      gradient-norm: 9681.93
      step size: 2.52057
      objective function value: 1.01531
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 57 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354635
      gradient-norm: 269.339
      step size: 2.28253
      objective function value: 0.97999
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 58 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354635
      gradient-norm: 7340
      step size: 2.44946
      objective function value: 1.00541
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 59 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354634
      gradient-norm: 5261.58
      step size: 2.50486
      objective function value: 0.987397
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 60 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354634
      gradient-norm: 9776.76
      step size: 2.83809
      objective function value: 0.99408
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 61 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354634
      gradient-norm: 3694.87
      step size: 2.71152
      objective function value: 0.986972
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 62 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354634
      gradient-norm: 14690.3
      step size: 3.20053
      objective function value: 1.02865
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 63 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354634
      gradient-norm: 5638.05
      step size: 3.16906
      objective function value: 0.989437
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 64 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354634
      gradient-norm: 1270.47
      step size: 2.90635
      objective function value: 0.981966
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 65 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354633
      gradient-norm: 7897.16
      step size: 2.99931
      objective function value: 0.997576
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 66 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354633
      gradient-norm: 1943.23
      step size: 2.77073
      objective function value: 0.98306
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 67 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354633
      gradient-norm: 2725.37
      step size: 2.61019
      objective function value: 0.983954
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 68 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354633
      gradient-norm: 2631.49
      step size: 2.43673
      objective function value: 0.986561
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 69 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354633
      gradient-norm: 19962.4
      step size: 3.58039
      objective function value: 1.03353
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 70 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354633
      gradient-norm: 4031.85
      step size: 3.38785
      objective function value: 0.987181
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 71 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354633
      gradient-norm: 3538.32
      step size: 3.1982
      objective function value: 0.986444
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 72 with 55 observations.
      Iteration 600: Reduce learning rate to 1e-05
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 1963.05
      step size: 2.88326
      objective function value: 0.982976
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 73 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 769.92
      step size: 2.59734
      objective function value: 0.981036
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 74 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 9602.93
      step size: 2.36481
      objective function value: 1.01369
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 75 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 1960.82
      step size: 2.13309
      objective function value: 0.982558
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 76 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 1998.46
      step size: 1.92596
      objective function value: 0.983547
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 77 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 13721
      step size: 1.78602
      objective function value: 1.0343
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 78 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 7416.58
      step size: 1.63922
      objective function value: 0.996439
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 79 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354632
      gradient-norm: 3045.06
      step size: 1.482
      objective function value: 0.985351
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 80 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 9325.8
      step size: 1.36524
      objective function value: 0.998993
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 81 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 13152.8
      step size: 1.28446
      objective function value: 1.03329
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 82 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 8023.95
      step size: 1.17976
      objective function value: 1.00025
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 83 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 1800.83
      step size: 1.06632
      objective function value: 0.983182
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 84 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 8398.45
      step size: 0.989245
      objective function value: 0.998056
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 85 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 2211.28
      step size: 0.895062
      objective function value: 0.984452
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 86 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 5387.12
      step size: 0.821726
      objective function value: 0.987025
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 87 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 677.308
      step size: 0.741749
      objective function value: 0.981107
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 88 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 700.184
      step size: 0.669711
      objective function value: 0.981647
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 89 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 4950.65
      step size: 0.623324
      objective function value: 0.991494
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 90 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 20994.5
      step size: 0.678054
      objective function value: 1.01968
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 91 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 8136.92
      step size: 0.646309
      objective function value: 0.997255
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 92 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 1677.43
      step size: 0.58621
      objective function value: 0.984485
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 93 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 982.597
      step size: 0.531332
      objective function value: 0.982203
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 94 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 4145.25
      step size: 0.490543
      objective function value: 0.988375
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 95 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 3428.74
      step size: 0.45609
      objective function value: 0.992909
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 96 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 10576.2
      step size: 0.465343
      objective function value: 1.03589
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 97 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 8130.49
      step size: 0.463413
      objective function value: 1.01496
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 98 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 2672.27
      step size: 0.427466
      objective function value: 0.98682
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 99 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 5430.09
      step size: 0.401387
      objective function value: 0.988075
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 100 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 4872.67
      step size: 0.38283
      objective function value: 0.988971
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 101 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 9867.5
      step size: 0.398848
      objective function value: 1.00961
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 102 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354631
      gradient-norm: 6107.86
      step size: 0.390119
      objective function value: 0.991485
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 103 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 212.358
      step size: 0.352264
      objective function value: 0.979864
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 104 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 879.762
      step size: 0.319602
      objective function value: 0.981114
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 105 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 2035.8
      step size: 0.293909
      objective function value: 0.983419
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 106 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 7749.32
      step size: 0.304334
      objective function value: 0.999555
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 107 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 4667.6
      step size: 0.298011
      objective function value: 0.992788
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 108 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 4796.62
      step size: 0.293722
      objective function value: 0.994031
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 109 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 1495.24
      step size: 0.271955
      objective function value: 0.983109
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 110 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 3772.48
      step size: 0.26036
      objective function value: 0.989141
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 111 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 4665.28
      step size: 0.256193
      objective function value: 0.990709
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 112 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 2453.11
      step size: 0.240124
      objective function value: 0.983603
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 113 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 4089.49
      step size: 0.237707
      objective function value: 0.988634
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 114 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 2477.11
      step size: 0.223326
      objective function value: 0.984116
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 115 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 7003.94
      step size: 0.245585
      objective function value: 0.999096
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 116 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 402.093
      step size: 0.222897
      objective function value: 0.980277
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 117 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 5104.76
      step size: 0.230879
      objective function value: 0.993349
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 118 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 3096.14
      step size: 0.22121
      objective function value: 0.984622
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 119 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 2967.28
      step size: 0.211863
      objective function value: 0.984725
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 120 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 3230.08
      step size: 0.204621
      objective function value: 0.98544
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 121 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 7862.29
      step size: 0.227892
      objective function value: 0.998816
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 122 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 1510.89
      step size: 0.211845
      objective function value: 0.982447
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 123 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 4004.76
      step size: 0.208473
      objective function value: 0.990791
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 124 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 1716.07
      step size: 0.195158
      objective function value: 0.984202
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 125 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 4152.38
      step size: 0.198824
      objective function value: 0.994196
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 126 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 3301.93
      step size: 0.193986
      objective function value: 0.990718
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 127 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 908.838
      step size: 0.178869
      objective function value: 0.981361
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 128 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 22062.9
      step size: 0.332862
      objective function value: 1.02903
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 129 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 8066.32
      step size: 0.337863
      objective function value: 1.00991
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 130 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 5756.47
      step size: 0.329137
      objective function value: 0.995551
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 131 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 13209.2
      step size: 0.370304
      objective function value: 1.0701
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 132 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 1437.03
      step size: 0.337973
      objective function value: 0.982679
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 133 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 6840.59
      step size: 0.336165
      objective function value: 0.995523
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 134 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 5588.45
      step size: 0.327908
      objective function value: 0.997061
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 135 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 5771.16
      step size: 0.318923
      objective function value: 0.991452
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 136 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 1267.59
      step size: 0.292538
      objective function value: 0.982899
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 137 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 4191.54
      step size: 0.279967
      objective function value: 0.990219
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 138 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 10494.6
      step size: 0.310881
      objective function value: 1.00592
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 139 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 11337.5
      step size: 0.347266
      objective function value: 1.03191
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 140 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 1897.71
      step size: 0.319572
      objective function value: 0.982276
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 141 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 1348.36
      step size: 0.294167
      objective function value: 0.982434
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 142 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 5999.51
      step size: 0.28988
      objective function value: 0.987943
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 143 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 5617.9
      step size: 0.285373
      objective function value: 0.992001
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 144 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 9783.67
      step size: 0.308399
      objective function value: 1.00395
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 145 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 1468.53
      step size: 0.282646
      objective function value: 0.983274
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 146 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 387.476
      step size: 0.256104
      objective function value: 0.98027
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 147 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 3100.69
      step size: 0.24642
      objective function value: 0.985898
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 148 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 3836.38
      step size: 0.2374
      objective function value: 0.98511
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 149 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 21004
      step size: 0.368823
      objective function value: 1.06683
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 150 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 5348.78
      step size: 0.354195
      objective function value: 0.995251
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 151 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 1117.92
      step size: 0.322965
      objective function value: 0.983416
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 152 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 1969.75
      step size: 0.297741
      objective function value: 0.984707
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 153 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 3283.68
      step size: 0.281544
      objective function value: 0.985544
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 154 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 13975.6
      step size: 0.346172
      objective function value: 1.01568
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 155 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354630
      gradient-norm: 18925.4
      step size: 0.433284
      objective function value: 1.04316
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 156 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 830.92
      step size: 0.392724
      objective function value: 0.981427
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 157 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 11594
      step size: 0.419285
      objective function value: 1.0051
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 158 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 7527.5
      step size: 0.4183
      objective function value: 1.00376
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 159 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 2929.92
      step size: 0.386652
      objective function value: 0.988482
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 160 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 4433.95
      step size: 0.367679
      objective function value: 0.989013
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 161 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 457.895
      step size: 0.33283
      objective function value: 0.980475
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 162 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 3233.9
      step size: 0.31102
      objective function value: 0.987938
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 163 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 1291.99
      step size: 0.28523
      objective function value: 0.982613
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 164 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 13233.7
      step size: 0.334893
      objective function value: 1.0293
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 165 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 2990.11
      step size: 0.31112
      objective function value: 0.989205
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 166 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 8171.57
      step size: 0.318697
      objective function value: 0.988528
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 167 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 3530.71
      step size: 0.300153
      objective function value: 0.990693
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 168 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 1669.88
      step size: 0.276362
      objective function value: 0.984655
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 169 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 1754.26
      step size: 0.255236
      objective function value: 0.983357
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 170 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 920.991
      step size: 0.231873
      objective function value: 0.980716
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 171 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 3679.54
      step size: 0.227082
      objective function value: 0.986915
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 172 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 693.664
      step size: 0.207017
      objective function value: 0.980773
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 173 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 6610.9
      step size: 0.224438
      objective function value: 0.994812
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 174 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 4711.46
      step size: 0.226913
      objective function value: 0.991727
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 175 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 6562.18
      step size: 0.235529
      objective function value: 0.994521
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 176 with 5 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 10951
      step size: 0.283628
      objective function value: 1.00488
      classification error rate: 0
    </neural-network.process-batch>
    Processed 9630 observations in 176 mini-batches.
  </neural-network.process-epoch>
  Start epoch 5
  <neural-network.process-epoch>
    <neural-network.process-batch>
      Process mini-batch 1 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 12767.1
      step size: 0.326692
      objective function value: 1.05095
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 2 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 5396.56
      step size: 0.319271
      objective function value: 0.992501
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 3 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 4256.44
      step size: 0.305411
      objective function value: 0.988875
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 4 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 335.839
      step size: 0.276431
      objective function value: 0.980028
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 5 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 7630.32
      step size: 0.2865
      objective function value: 0.993024
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 6 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 539.64
      step size: 0.260313
      objective function value: 0.980915
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 7 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 3630.32
      step size: 0.249932
      objective function value: 0.986822
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 8 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 1356.38
      step size: 0.230798
      objective function value: 0.982078
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 9 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 965.251
      step size: 0.211579
      objective function value: 0.982236
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 10 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 5239.2
      step size: 0.217854
      objective function value: 0.991987
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 11 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 18858.2
      step size: 0.330882
      objective function value: 1.05824
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 12 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 1636.1
      step size: 0.303662
      objective function value: 0.982993
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 13 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 10639
      step size: 0.329783
      objective function value: 1.01889
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 14 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 736.993
      step size: 0.300252
      objective function value: 0.981667
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 15 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 1965.39
      step size: 0.278318
      objective function value: 0.984099
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 16 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 10889
      step size: 0.318627
      objective function value: 1.01885
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 17 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 1405.79
      step size: 0.293059
      objective function value: 0.983054
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 18 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 4348.26
      step size: 0.281809
      objective function value: 0.990329
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 19 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 8134.08
      step size: 0.294331
      objective function value: 1.00417
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 20 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 255.38
      step size: 0.26629
      objective function value: 0.979963
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 21 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 589.03
      step size: 0.242372
      objective function value: 0.980755
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 22 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 2485.12
      step size: 0.226889
      objective function value: 0.986443
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 23 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 432.901
      step size: 0.205961
      objective function value: 0.980435
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 24 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 610.119
      step size: 0.188239
      objective function value: 0.980879
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 25 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 5080.36
      step size: 0.192779
      objective function value: 0.987241
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 26 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 992.037
      step size: 0.177769
      objective function value: 0.981935
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 27 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 10265.3
      step size: 0.228328
      objective function value: 1.00128
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 28 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 2906.22
      step size: 0.216708
      objective function value: 0.984858
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 29 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 11800.8
      step size: 0.267267
      objective function value: 1.00967
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 30 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354629
      gradient-norm: 2656.28
      step size: 0.251133
      objective function value: 0.985267
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 31 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 2329.6
      step size: 0.232302
      objective function value: 0.984783
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 32 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 312.906
      step size: 0.210748
      objective function value: 0.98012
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 33 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 5894.89
      step size: 0.221168
      objective function value: 0.990574
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 34 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 11371.8
      step size: 0.272693
      objective function value: 0.99774
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 35 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 271.461
      step size: 0.246828
      objective function value: 0.980014
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 36 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 1091.69
      step size: 0.22683
      objective function value: 0.981475
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 37 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 2560.62
      step size: 0.215506
      objective function value: 0.988498
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 38 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 6040.69
      step size: 0.222236
      objective function value: 0.99624
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 39 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 420.594
      step size: 0.20196
      objective function value: 0.980478
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 40 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 2415.01
      step size: 0.190642
      objective function value: 0.986069
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 41 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 1867
      step size: 0.178424
      objective function value: 0.982957
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 42 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 1264.27
      step size: 0.166115
      objective function value: 0.983621
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 43 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 2008.25
      step size: 0.158995
      objective function value: 0.986958
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 44 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 727.234
      step size: 0.145957
      objective function value: 0.981086
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 45 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 5319.53
      step size: 0.159055
      objective function value: 0.992364
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 46 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 10049.3
      step size: 0.21391
      objective function value: 1.01339
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 47 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 5596.64
      step size: 0.218867
      objective function value: 0.992414
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 48 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 13441.8
      step size: 0.28329
      objective function value: 1.02569
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 49 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 4057.88
      step size: 0.275626
      objective function value: 0.992265
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 50 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 4267.49
      step size: 0.269494
      objective function value: 0.997409
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 51 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 4557.79
      step size: 0.262649
      objective function value: 0.989427
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 52 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 7478.27
      step size: 0.274997
      objective function value: 0.998492
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 53 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 5110.25
      step size: 0.273737
      objective function value: 0.991044
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 54 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 1452.06
      step size: 0.251134
      objective function value: 0.983479
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 55 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 1742.48
      step size: 0.231134
      objective function value: 0.983679
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 56 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 3044.74
      step size: 0.220169
      objective function value: 0.988244
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 57 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 570.886
      step size: 0.200658
      objective function value: 0.981009
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 58 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 12192.2
      step size: 0.263825
      objective function value: 1.00582
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 59 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 427.127
      step size: 0.239364
      objective function value: 0.980463
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 60 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 1805.18
      step size: 0.221546
      objective function value: 0.984694
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 61 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 4250.12
      step size: 0.218643
      objective function value: 0.98681
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 62 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 495.358
      step size: 0.198965
      objective function value: 0.980369
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 63 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 1092.59
      step size: 0.183435
      objective function value: 0.980969
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 64 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 350.899
      step size: 0.166798
      objective function value: 0.980252
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 65 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 459.873
      step size: 0.152287
      objective function value: 0.980322
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 66 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 260.939
      step size: 0.13844
      objective function value: 0.979957
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 67 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 418.079
      step size: 0.126731
      objective function value: 0.980593
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 68 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 2962.4
      step size: 0.130372
      objective function value: 0.986125
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 69 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 9201.21
      step size: 0.185481
      objective function value: 1.00409
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 70 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 1011.94
      step size: 0.17171
      objective function value: 0.981962
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 71 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 1161.58
      step size: 0.159436
      objective function value: 0.982064
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 72 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 2392.15
      step size: 0.154641
      objective function value: 0.985893
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 73 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 7108.73
      step size: 0.181177
      objective function value: 1.0045
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 74 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 2000.33
      step size: 0.171167
      objective function value: 0.98368
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 75 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 2360.09
      step size: 0.164278
      objective function value: 0.985272
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 76 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 1115.51
      step size: 0.152436
      objective function value: 0.98165
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 77 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 3167.96
      step size: 0.153892
      objective function value: 0.992496
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 78 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 891.971
      step size: 0.14232
      objective function value: 0.981224
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 79 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 3149.91
      step size: 0.1451
      objective function value: 0.985698
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 80 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 510.102
      step size: 0.132915
      objective function value: 0.980425
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 81 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 4646.82
      step size: 0.144624
      objective function value: 0.994522
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 82 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 1554.09
      step size: 0.138176
      objective function value: 0.982974
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 83 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 512.133
      step size: 0.126952
      objective function value: 0.980367
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 84 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 5128.49
      step size: 0.145889
      objective function value: 0.989277
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 85 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 2417.07
      step size: 0.143326
      objective function value: 0.985833
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 86 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 7211.29
      step size: 0.175777
      objective function value: 1.00037
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 87 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354628
      gradient-norm: 6353.8
      step size: 0.198339
      objective function value: 0.998628
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 88 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 868.057
      step size: 0.182118
      objective function value: 0.981086
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 89 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 20859
      step size: 0.329796
      objective function value: 1.03523
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 90 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 2523.93
      step size: 0.301746
      objective function value: 0.985252
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 91 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 245.76
      step size: 0.27286
      objective function value: 0.979912
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 92 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 301.494
      step size: 0.247239
      objective function value: 0.980038
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 93 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 1895.02
      step size: 0.231625
      objective function value: 0.98473
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 94 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 6207.86
      step size: 0.241112
      objective function value: 0.990647
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 95 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 2376.07
      step size: 0.227418
      objective function value: 0.982549
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 96 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 460.193
      step size: 0.206882
      objective function value: 0.98057
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 97 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 3689.31
      step size: 0.201636
      objective function value: 0.987549
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 98 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 9265.12
      step size: 0.23918
      objective function value: 0.997374
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 99 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 7417.9
      step size: 0.252962
      objective function value: 1.00283
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 100 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 475.225
      step size: 0.229689
      objective function value: 0.980493
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 101 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 3205.52
      step size: 0.222165
      objective function value: 0.987761
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 102 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 926.321
      step size: 0.203832
      objective function value: 0.981807
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 103 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 1048.15
      step size: 0.187727
      objective function value: 0.982307
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 104 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 6207.12
      step size: 0.198598
      objective function value: 0.991535
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 105 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 326.716
      step size: 0.180341
      objective function value: 0.980026
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 106 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 1377.38
      step size: 0.166661
      objective function value: 0.982603
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 107 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 1446.23
      step size: 0.156255
      objective function value: 0.982756
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 108 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 985.273
      step size: 0.145278
      objective function value: 0.983601
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 109 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 2259.71
      step size: 0.143084
      objective function value: 0.98556
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 110 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 23693.6
      step size: 0.324379
      objective function value: 1.15422
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 111 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 4964.95
      step size: 0.31312
      objective function value: 0.994676
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 112 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 1013.79
      step size: 0.285986
      objective function value: 0.981267
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 113 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 8187.12
      step size: 0.300898
      objective function value: 0.999828
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 114 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 14680.8
      step size: 0.368913
      objective function value: 1.01568
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 115 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 8626.71
      step size: 0.37114
      objective function value: 0.995885
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 116 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 528.832
      step size: 0.336117
      objective function value: 0.98078
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 117 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 9769.32
      step size: 0.35442
      objective function value: 1.05323
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 118 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 1835.94
      step size: 0.325091
      objective function value: 0.983006
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 119 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 5509.12
      step size: 0.315556
      objective function value: 0.99262
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 120 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 3102.28
      step size: 0.296424
      objective function value: 0.987854
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 121 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 874.844
      step size: 0.270139
      objective function value: 0.981424
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 122 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 4245.77
      step size: 0.261393
      objective function value: 0.985748
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 123 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 7718.82
      step size: 0.28052
      objective function value: 1.00048
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 124 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 4558.33
      step size: 0.273697
      objective function value: 0.990477
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 125 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 1533.03
      step size: 0.25143
      objective function value: 0.983928
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 126 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 4082.14
      step size: 0.247249
      objective function value: 0.988712
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 127 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 19963.3
      step size: 0.35486
      objective function value: 1.05173
      classification error rate: 0.0363636
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 128 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 3705.71
      step size: 0.333031
      objective function value: 0.990229
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 129 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 11526.7
      step size: 0.37317
      objective function value: 1.00911
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 130 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 12950.1
      step size: 0.412691
      objective function value: 1.03646
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 131 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 8195.23
      step size: 0.405755
      objective function value: 1.00301
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 132 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 933.744
      step size: 0.368331
      objective function value: 0.981112
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 133 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 10000.1
      step size: 0.384329
      objective function value: 1.00065
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 134 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 435.252
      step size: 0.347896
      objective function value: 0.98022
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 135 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 4653.76
      step size: 0.33455
      objective function value: 0.989131
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 136 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 3041.04
      step size: 0.314089
      objective function value: 0.98924
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 137 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 1028.92
      step size: 0.286531
      objective function value: 0.982
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 138 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354627
      gradient-norm: 731.046
      step size: 0.260052
      objective function value: 0.980618
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 139 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 4339.83
      step size: 0.255092
      objective function value: 0.987901
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 140 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 7313.84
      step size: 0.269361
      objective function value: 0.997162
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 141 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 3321.98
      step size: 0.255026
      objective function value: 0.987637
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 142 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 3586.15
      step size: 0.247014
      objective function value: 0.990553
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 143 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 1082.24
      step size: 0.226616
      objective function value: 0.981722
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 144 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 1376.25
      step size: 0.210518
      objective function value: 0.983012
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 145 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 1011.45
      step size: 0.193874
      objective function value: 0.981567
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 146 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 1365.13
      step size: 0.180496
      objective function value: 0.982162
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 147 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 4636.02
      step size: 0.184571
      objective function value: 0.990858
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 148 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 2418.36
      step size: 0.1776
      objective function value: 0.983579
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 149 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 532.635
      step size: 0.16249
      objective function value: 0.981114
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 150 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 10857
      step size: 0.223659
      objective function value: 1.01612
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 151 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 3119.02
      step size: 0.213943
      objective function value: 0.98805
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 152 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 2583.97
      step size: 0.20241
      objective function value: 0.985236
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 153 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 9007.15
      step size: 0.238856
      objective function value: 1.00046
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 154 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 2194.48
      step size: 0.224555
      objective function value: 0.982672
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 155 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 2266.89
      step size: 0.211812
      objective function value: 0.985374
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 156 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 7759.55
      step size: 0.238558
      objective function value: 0.990644
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 157 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 1935.04
      step size: 0.223239
      objective function value: 0.98658
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 158 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 4725.37
      step size: 0.224033
      objective function value: 0.999549
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 159 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 9652.29
      step size: 0.257847
      objective function value: 1.00073
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 160 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 1188.17
      step size: 0.23688
      objective function value: 0.982311
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 161 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 1911.23
      step size: 0.2209
      objective function value: 0.982736
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 162 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 8127.64
      step size: 0.246834
      objective function value: 1.01568
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 163 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 197.508
      step size: 0.223374
      objective function value: 0.979768
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 164 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 1720.3
      step size: 0.208582
      objective function value: 0.983716
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 165 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 11309
      step size: 0.265973
      objective function value: 1.03079
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 166 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 6993.91
      step size: 0.277351
      objective function value: 0.999071
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 167 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 15210.2
      step size: 0.337759
      objective function value: 1.0066
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 168 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 11751.1
      step size: 0.37059
      objective function value: 1.00548
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 169 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 704.175
      step size: 0.336219
      objective function value: 0.980874
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 170 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 11844.9
      step size: 0.363656
      objective function value: 0.997755
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 171 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 1751.11
      step size: 0.333801
      objective function value: 0.982904
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 172 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 2982.29
      step size: 0.311983
      objective function value: 0.986652
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 173 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 2796.63
      step size: 0.290389
      objective function value: 0.987121
      classification error rate: 0
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 174 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 13065.7
      step size: 0.339797
      objective function value: 1.02723
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 175 with 55 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 9038.94
      step size: 0.348197
      objective function value: 1.00996
      classification error rate: 0.0181818
    </neural-network.process-batch>
    <neural-network.process-batch>
      Process mini-batch 176 with 5 observations.
      parameter-norm (l1-norm of all trainable weights and biases): 354626
      gradient-norm: 840.159
      step size: 0.316237
      objective function value: 0.981003
      classification error rate: 0
    </neural-network.process-batch>
    Processed 9630 observations in 176 mini-batches.
  </neural-network.process-epoch>
  Layer relu1_1:port-0: write bias to results/bias-relu1_1.vector.gz
  Layer relu1_2:port-0: write bias to results/bias-relu1_2.vector.gz
  Layer relu2_1:port-0: write bias to results/bias-relu2_1.vector.gz
  Layer relu2_2:port-0: write bias to results/bias-relu2_2.vector.gz
  Layer relu3_1:port-0: write bias to results/bias-relu3_1.vector.gz
  Layer relu3_2:port-0: write bias to results/bias-relu3_2.vector.gz
  Layer relu3_3:port-0: write bias to results/bias-relu3_3.vector.gz
  Layer relu4_1:port-0: write bias to results/bias-relu4_1.vector.gz
  Layer relu4_2:port-0: write bias to results/bias-relu4_2.vector.gz
  Layer relu4_3:port-0: write bias to results/bias-relu4_3.vector.gz
  Layer relu5_1:port-0: write bias to results/bias-relu5_1.vector.gz
  Layer relu5_2:port-0: write bias to results/bias-relu5_2.vector.gz
  Layer relu5_3:port-0: write bias to results/bias-relu5_3.vector.gz
  Layer layer-6:port-0: write bias to results/bias-layer-6.vector.gz
  Layer layer-7:port-0: write bias to results/bias-layer-7.vector.gz
  Layer layer-8:port-0: write bias to results/bias-layer-8.vector.gz
  Connection conv1_1: write weight matrix to results/weights-conv1_1.matrix.gz
  Connection conv1_2: write weight matrix to results/weights-conv1_2.matrix.gz
  Connection conv2_1: write weight matrix to results/weights-conv2_1.matrix.gz
  Connection conv2_2: write weight matrix to results/weights-conv2_2.matrix.gz
  Connection conv3_1: write weight matrix to results/weights-conv3_1.matrix.gz
  Connection conv3_2: write weight matrix to results/weights-conv3_2.matrix.gz
  Connection conv3_3: write weight matrix to results/weights-conv3_3.matrix.gz
  Connection conv4_1: write weight matrix to results/weights-conv4_1.matrix.gz
  Connection conv4_2: write weight matrix to results/weights-conv4_2.matrix.gz
  Connection conv4_3: write weight matrix to results/weights-conv4_3.matrix.gz
  Connection conv5_1: write weight matrix to results/weights-conv5_1.matrix.gz
  Connection conv5_2: write weight matrix to results/weights-conv5_2.matrix.gz
  Connection conv5_3: write weight matrix to results/weights-conv5_3.matrix.gz
  Connection fc6: write weight matrix to results/weights-fc6.matrix.gz
  Connection fc7: write weight matrix to results/weights-fc7.matrix.gz
  Connection fc8: write weight matrix to results/weights-fc8.matrix.gz
</neural-network.process-all-epochs>
